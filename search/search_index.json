{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to the Scrapegoat documentation! This documentation will guide you through all there is to know about Scrapegoat, from installation to advanced usage.</p> <p>Read on to discover how Scrapegoat can revolutionize your webscraping experience.</p>"},{"location":"#the-problem-with-webscraping-today","title":"The Problem with Webscraping Today","text":"<p>The webscraping experience is awful; it has been for a long time. Scrapers are brittle, repetitive, and full of boilerplate. Even simple tasks require dozens of lines of glue code just to fetch a page, parse it, and walk the DOM.</p> <p>Imagine if, everytime you wanted to pull data from a database, you had to write code to connect to the database, write code to traverse the table and find your data, and then parse the results into a usable format. Nobody would put up with that, yet that's exactly what we do when scraping the web.</p> <p>Webscraping with BeautifulSoup</p> <p>This code fetches a recipe page and extracts the list of ingredients into a CSV file, ignoring the \"Deselect All\" option contained in the list.</p> <pre><code>import requests\nimport csv\nfrom bs4 import BeautifulSoup\n\n\nurl = \"https://www.foodnetwork.com/recipes/food-network-kitchen/baked-feta-pasta-9867689\"\nresponse = requests.get(url, headers={\n    \"User-Agent\": \"Mozilla/5.0 (Scrapegoat)\",\n    \"Accept-Language\": \"en-US,en;q=0.9\",\n    \"Accept-Encoding\": \"gzip, deflate, br\",\n    \"Connection\": \"keep-alive\",\n    \"Accept\": \"*/*\",\n    \"DNT\": \"1\",\n    \"Upgrade-Insecure-Requests\": \"1\",\n    \"Sec-Fetch-Dest\": \"document\",\n    \"Sec-Fetch-Mode\": \"navigate\",\n})\nresponse.raise_for_status()\n\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\ningredient_spans = soup.select(\"span.o-Ingredients__a-Ingredient--CheckboxLabel\")\n\ningredients = []\nfor span in ingredient_spans:\n    body = span.get_text(strip=True)\n    if body.lower() != \"deselect all\":\n        ingredients.append(body)\n\nwith open(\"ingredients.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"body\"])\n    writer.writerows([[ing] for ing in ingredients])\n</code></pre> <p>As you can see, even for a simple task like extracting ingredients from a recipe page, we have to write a lot of boilerplate code to handle HTTP requests, parse HTML, navigate the DOM, and write to a CSV file. With more complex tasks, the code only gets longer and more unwieldy. Stacking this up over multiple pages or sites quickly becomes a nightmare.</p>"},{"location":"#the-scrapegoat-solution","title":"The Scrapegoat Solution","text":"<p>Scrapegoat started with a question: Why can't we query web pages like we query a database?</p>"},{"location":"#query-centric-design","title":"Query-Centric Design","text":"<p>Scrapegoat is designed with the query at the center. You shouldn't have to write boilerplate, string libraries together, or even think about the underlying plumbing. With Scrapegoat, you write queries that express what data you want to extract, and Scrapegoat takes care of how to get it.</p> <p>Webscraping with Scrapegoat</p> <pre><code>from scrapegoat import Shepherd\n\nquery = \"\"\"\n    VISIT \"https://example.com\";\n    SCRAPE a IN table;\n    EXTRACT href;\n    OUTPUT json --filename 'links';\n    \"\"\"\nresults = Shepherd().herd(query)\n</code></pre> <p>Running Scrapegoat from the Command Line</p> <p>You can even run our package through the CLI!</p> <pre><code>scrapegoat path/to/file.goat\n</code></pre>"},{"location":"#goatspeak-the-querying-language-for-scrapegoat","title":"Goatspeak: The Querying Language for Scrapegoat","text":"<p>At the heart of Scrapegoat is Goatspeak, a domain-specific language (DSL) designed specifically for webscraping. Goatspeak allows you to express complex scraping tasks in a concise and readable way.</p> <p>We pride ourselves on ensuring Goatspeak is easy to learn, even for those new to webscraping.  With only 5 commands, Goatspeak allows you to fetch pages, navigate the DOM, extract data, and structure the results exactly how you want them.</p> <p>Below is that same example from earlier. However, this time with a query, the Scrapegoat way:</p> <p>Goatspeak Query Example</p> <pre><code>VISIT \"https://www.foodnetwork.com/recipes/food-network-kitchen/baked-feta-pasta-9867689\";\nSCRAPE span IF @class=\"o-Ingredients__a-Ingredient--CheckboxLabel\" IF body != \"Deselect All\";\nEXTRACT body;\nOUTPUT csv --filename \"ingredients\";\n</code></pre>"},{"location":"#loom-a-graphical-interface-for-building-goatspeak-queries","title":"Loom: A Graphical Interface for Building Goatspeak Queries","text":"<p>However, if building queries isn't your style, Scrapegoat also provides an entirely code-free experience through our Loom extension, which offers a graphical interface for building and running Goatspeak queries.</p> <p>Furthermore, Goatspeak queries are designed to be portable and reusable. Simply save a query into a <code>.goat</code> file, and it can be shared and run anywhere Scrapegoat is installed.</p>"},{"location":"#enhanced-development-experience-with-linter-and-lsp","title":"Enhanced Development Experience with Linter and LSP","text":"<p>To further improve your development experience with Scrapegoat, we offer a linter and Language Server Protocol (LSP) extension. The linter helps you catch syntax errors and potential issues in your Goatspeak scripts before you run them, while the LSP extension provides features like autocompletion, go-to-definition, and inline documentation within your code editor.</p>"},{"location":"#extendability","title":"Extendability","text":"<p>Scrapegoat is designed to be extendable.  Each command in Goatspeak is run through a submanager, all of which are open to extension to add new functionality. Our documentation goes over extensively how and where to add new features to Scrapegoat, to ensure you receive the richest webscraping experience possible.</p>"},{"location":"#feature-summary","title":"Feature Summary","text":"<ul> <li>Concise Queries: Extract data with just a few lines of Goatspeak code.</li> <li>Easy to Learn: Simple syntax with only 5 core commands.</li> <li>Code-Free Option: Use the Loom extension for a graphical interface.</li> <li>Portable Scripts: Save and share <code>.goat</code> files easily.</li> <li>Enhanced Development: Linter and LSP support for a better coding experience.</li> <li>Extendable: Easily add new features and commands to Scrapegoat.</li> <li>JavaScript Site Support: Built-in support for scraping JavaScript-rendered pages using a headless browser.</li> <li>Multiple Output Formats: Export scraped data in various formats like JSON or CSV.</li> <li>Command-Line Interface: Run Goatspeak queries directly from the terminal.</li> </ul> <p>Building webscrapers with Scrapegoat becomes a joy, not a chore. To get started, check out our installation guide and start writing your first Goatspeak query today!</p>"},{"location":"#useful-links","title":"Useful Links","text":"<p>Below are all of Scrapegoat's links in one place for your convenience:</p> <ul> <li>GitHub Repository</li> <li>Documentation Home</li> <li>Scrapegoat Core PyPI Package</li> <li>Scrapegoat Loom PyPI Package</li> <li>License</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Welcome to the installation guide! This page will walk you through how to install all of the features from the Scrapegoat ecosystem. Follow the steps below to set up the software on your system.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure that you have the following prerequisites installed on your system:</p> <ul> <li>Python (version 3.7 or higher)</li> <li>pip</li> <li>Playwright (Optional by default, required for JavaScript rendering support)</li> </ul> <p>Check Python Version</p> <p>You can check your Python version by running.</p> <pre><code>python --version\n</code></pre>"},{"location":"installation/#core-installation","title":"Core Installation","text":""},{"location":"installation/#install-the-core-package","title":"Install the Core Package","text":"<p>To install the core package, run the following command in your terminal: <pre><code>pip install scrapegoat-core\n</code></pre></p>"},{"location":"installation/#optional-install-with-playwright-support","title":"Optional: Install with Playwright Support","text":"<p>If you want to use Playwright for browser automation, you can install the package with Playwright support by running: <pre><code>pip install scrapegoat-core[js]\n</code></pre></p>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>To verify that the installation was successful, you can run the following command: <pre><code>scrapegoat -h\n</code></pre> This should display the help message for the Scrapegoat command-line interface. If you see the help message, congratulations! You have successfully installed Scrapegoat.</p> <p>Scrapegoat Installation Successful</p> <p>If you see the help message, congratulations! You have successfully installed Scrapegoat.</p> <pre><code>usage: scrapegoat [-h] [-v] [-j] [file_or_query]\n\nScrapegoat language executor\n\npositional arguments:\n    file_or_query     Path to a .goat file or a raw query as a string\n\noptions:\n    -h, --help        show this help message and exit\n    -v, --verbose     Prints the results of the query to the console\n    -j, --javascript  Uses a headless browser to support javascript rendered pages\n</code></pre>"},{"location":"installation/#loom-installation-optional","title":"Loom Installation (Optional)","text":"<p>Loom is an optional extension that provides additional features for Scrapegoat.</p>"},{"location":"installation/#install-loom","title":"Install Loom","text":"<p>To install Loom, run the following command: <pre><code>pip install scrapegoat-loom\n</code></pre></p>"},{"location":"installation/#installing-scrapegoat-with-loom-support","title":"Installing Scrapegoat with Loom Support","text":"<p>Alternatively, you can install Scrapegoat with Loom support by running: <pre><code>pip install scrapegoat-core[loom]\n</code></pre></p>"},{"location":"installation/#verify-loom-installation","title":"Verify Loom Installation","text":"<p>To verify that Loom was installed successfully, you can run the following command: <pre><code>loom -h\n</code></pre> This should display the help message for the Loom command-line interface.</p> <p>Loom Installation Successful</p> <p>If you see the help message, congratulations! You have successfully installed Loom.</p> <pre><code>usage: loom [-h]\n\nScrapegoat language executor\n\noptions:\n-h, --help  show this help message and exit\n</code></pre>"},{"location":"installation/#linter-and-lsp-installation-optional","title":"Linter and LSP Installation (Optional)","text":"<p>Scrapegoat also offers a linter and Language Server Protocol (LSP) extension for enhanced development experience. </p>"},{"location":"installation/#installation-via-github","title":"Installation via GitHub","text":"<p>Currently our LSP and linter extensions are not available on the VSCode marketplace. To install the Goatspeak linter and LSP extension, follow these steps:</p> <ol> <li>Clone the Scrapegoat repository using the command below. <pre><code>git clone \"https://github.com/armanchinai/scrapegoat.git\"\n</code></pre></li> <li>Open VSCode and go to the Extensions view by clicking on the Extensions icon in the Activity Bar on the side of the window or by pressing <code>Ctrl+Shift+X</code>.</li> <li>Click on the three-dot menu in the top-right corner of the Extensions view and select \"Install from VSIX...\".</li> <li>Navigate to the cloned <code>scrapegoat</code> repository and find the <code>goatspeak-language-support</code> folder.</li> <li>Select the <code>goatspeak-language-support</code> folder and click \"Open\" to install the extension.</li> </ol>"},{"location":"installation/#verify-linter-and-lsp-installation","title":"Verify Linter and LSP Installation","text":"<p>To verify that the linter and LSP extension is working, open a <code>.goat</code> file in VSCode. </p> <p>Goatspeak Linter and LSP Installation Successful</p> <p>You should see syntax highlighting and linting suggestions as you type.</p>"},{"location":"installation/#conclusion","title":"Conclusion","text":"<p>You have now successfully installed Scrapegoat and its optional extensions. You can start using Scrapegoat for your web scraping needs. For more information on how to use Scrapegoat, take a peak at our tutorials to begin using Scrapegoat.</p>"},{"location":"core/","title":"Scrapegoat Core Documentation","text":""},{"location":"core/#introduction","title":"Introduction","text":"<p>This section of the documentation covers the documentation for the core Scrapegoat package. The core package provides the fundamental features and functionalities of Scrapegoat.</p> <p>For added scraping joy, this package has been goat themed. After all, goats are known for their agility and ability to navigate difficult terrain, much like how Scrapegoat helps you navigate the complexities of webscraping.</p>"},{"location":"core/#scrapegoat-architecture-overview","title":"Scrapegoat Architecture Overview","text":"<p>Scrapegoat is built around a modular OOP architecture that separates concerns into different components.</p>"},{"location":"core/#submanagers","title":"Submanagers","text":"<p>Most users will primarily interact with the Shepherd class, which serves as the main entry point for executing Goatspeak queries.  However, under the hood, Scrapegoat is composed of several submanagers, each responsible for handling specific commands in Goatspeak.</p> <ul> <li>Goat: The submanager responsible for handling scrape and select operations.</li> <li>Sheepdog: The submanager responsible for handling visit operations.</li> <li>Milkmaid: The submanager responsible for handling extract operations.</li> <li>Milkman: The submanager responsible for handling file I/O operations.</li> <li>Gardener: The submanager responsible for handling the conversion of HTML strings into HTMLNode objects.</li> </ul>"},{"location":"core/#language-utility-classes","title":"Language Utility Classes","text":"<p>Supporting these submanagers are several language utility classes that represent the core constructs of the Goatspeak language.</p> <ul> <li>Query: The class representing an individual query.</li> <li>GoatspeakBlock: A group of queries to be executed as a block.</li> <li>Command: The base class for all Goatspeak commands.<ul> <li>FetchCommand: The class representing the VISIT command.</li> <li>GrazeCommand: The class representing the SELECT and SCRAPE commands.</li> <li>ChurnCommand: The class representing the EXTRACT command.</li> <li>DeliverCommand: The class representing the OUTPUT command.</li> </ul> </li> <li>Condition: The base class for all conditional statements in Goatspeak.<ul> <li>IfCondition: The class representing an IF conditional statement.</li> <li>InCondition: The class representing an IN conditional statement</li> </ul> </li> <li>HTMLNode: The class representing an HTML element in the DOM.</li> </ul>"},{"location":"core/#interpreter-utility-classes","title":"Interpreter Utility Classes","text":"<p>Finally, several utility classes assist in interpreting and executing Goatspeak queries.</p> <ul> <li>Interpreter: The class responsible for interpreting and executing Goatspeak queries.</li> <li>Parser: The base class responsible for parsing Goatspeak queries into command objects.<ul> <li>FlagParser: The class responsible for parsing flags in Goatspeak commands.</li> <li>ConditionParser: The class responsible for parsing conditional statements in Goatspeak commands.</li> <li>ScrapeSelectParser: The class responsible for parsing SCRAPE and SELECT commands in Goatspeak.</li> <li>ExtractParser: The class responsible for parsing EXTRACT commands in Goatspeak.</li> <li>OutputParser: The class responsible for parsing OUTPUT commands in Goatspeak.</li> <li>VisitParser: The class responsible for parsing VISIT commands in Goatspeak.</li> </ul> </li> <li>Tokenizer: The class responsible for tokenizing Goatspeak queries into individual tokens.</li> <li>Token: The class representing an individual token in a Goatspeak query.</li> <li>TokenType: An enumeration of all possible token types in Goatspeak.</li> </ul>"},{"location":"core/#further-reading","title":"Further Reading","text":"<p>To learn more about each of these components, please refer to their respective documentation pages linked above.</p>"},{"location":"core/exceptions/","title":"Exceptions","text":""},{"location":"core/exceptions/#scrapegoatcoreexception","title":"ScrapegoatCoreException","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for Scrapegoat Core-related errors.</p> Note <p>This class serves as the base for all custom exceptions in the Scrapegoat Core module. All other exception classes should inherit from this class to ensure consistency and proper error handling within the Scrapegoat Core module.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatCoreException(Exception):\n    \"\"\"\n    Base exception class for Scrapegoat Core-related errors.\n\n    Note:\n        This class serves as the base for all custom exceptions in the Scrapegoat Core module. All other exception classes should inherit from this class to ensure consistency and proper error handling within the Scrapegoat Core module.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#scrapegoatplaywrightexception","title":"ScrapegoatPlaywrightException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for Scrapegoat Playwright-related errors. </p> Note <p>These exceptions can only be encountered when using HeadlessSheepdog or another implementation of the Sheepdog class that relies on Playwright for browser automation.</p> Example <pre><code>HeadlessSheepdog.fetch(\"https://example.com\")\n    ScrapegoatPlaywrightException: Playwright is not installed. Please install it with 'pip install playwright'\n</code></pre> Example <pre><code>HeadlessSheepdog.fetch(\"https://example.com\")\n    ScrapegoatPlaywrightException: Playwright browser executables are not installed. Please run 'playwright install' to install them.\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatPlaywrightException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for Scrapegoat Playwright-related errors. \n\n    Note:\n        These exceptions can only be encountered when using HeadlessSheepdog or another implementation of the Sheepdog class that relies on Playwright for browser automation.\n\n    Example:\n        ```python\n        HeadlessSheepdog.fetch(\"https://example.com\")\n            ScrapegoatPlaywrightException: Playwright is not installed. Please install it with 'pip install playwright'\n        ```\n\n    Example:\n        ```python\n        HeadlessSheepdog.fetch(\"https://example.com\")\n            ScrapegoatPlaywrightException: Playwright browser executables are not installed. Please run 'playwright install' to install them.\n        ```\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#scrapegoatioexception","title":"ScrapegoatIOException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for Scrapegoat I/O-related errors.</p> Example <pre><code>HeadlessSheepdog.fetch(\"file:///non_existent_file.html\")\n    ScrapegoatIOException: File not found: /non_existent_file.html\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatIOException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for Scrapegoat I/O-related errors.\n\n    Example:\n        ```python\n        HeadlessSheepdog.fetch(\"file:///non_existent_file.html\")\n            ScrapegoatIOException: File not found: /non_existent_file.html\n        ```\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#scrapegoatparseexception","title":"ScrapegoatParseException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for Scrapegoat HTML parsing-related errors.</p> Note <p>Raised when there is an issue parsing HTML content into a tree of HTMLNodes.</p> Example <pre><code>html_content = \"SomeMalformedHTMLString\"\nGardener.grow_tree(html_content)\n    ScrapegoatParseException: Failed to parse HTML content: Unexpected end tag\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatParseException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for Scrapegoat HTML parsing-related errors.\n\n    Note:\n        Raised when there is an issue parsing HTML content into a tree of HTMLNodes.\n\n    Example:\n        ```python\n        html_content = \"SomeMalformedHTMLString\"\n        Gardener.grow_tree(html_content)\n            ScrapegoatParseException: Failed to parse HTML content: Unexpected end tag\n        ```\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#scrapegoatmissingfieldexception","title":"ScrapegoatMissingFieldException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for missing tag errors in Scrapegoat.</p> Note <p>Raised when a command required extra information that was not provided in the goatspeak query. This can only happen with conditions, and needs to be forcefully done. May occur when manually constructing commands.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatMissingFieldException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for missing tag errors in Scrapegoat.\n\n    Note:\n        Raised when a command required extra information that was not provided in the goatspeak query. This can only happen with conditions, and needs to be forcefully done. May occur when manually constructing commands.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#scrapegoatfetchexception","title":"ScrapegoatFetchException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for Scrapegoat fetching-related errors.</p> Example <pre><code>HeadlessSheepdog.fetch(\"https://nonexistentwebsite.example\")\n    ScrapegoatFetchException: Failed to fetch URL 'https://nonexistentwebsite.example': DNS resolution failed\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class ScrapegoatFetchException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for Scrapegoat fetching-related errors.\n\n    Example:\n        ```python\n        HeadlessSheepdog.fetch(\"https://nonexistentwebsite.example\")\n            ScrapegoatFetchException: Failed to fetch URL 'https://nonexistentwebsite.example': DNS resolution failed\n        ```\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/exceptions/#goatspeakinterpreterexception","title":"GoatspeakInterpreterException","text":"<p>               Bases: <code>ScrapegoatCoreException</code></p> <p>Exception class for Scrapegoat Goatspeak interpreter-related errors.</p> Note <p>Raised when there is an error interpreting or executing Goatspeak commands. This could be due to syntax, semantic, or runtime issues within the Goatspeak language.</p> Example <pre><code>Shepherd.herd(\"\"VISIT 'https://example.com';SCRAPE p\")\n    GoatspeakInterpreterException: Missing semicolon at the end of the command.\n</code></pre> Example <pre><code>Shepherd.herd(\"VISIT 'https://example.com';SCRAPE p IN POSITION;\")\n    GoatspeakInterpreterException: Error parsing command starting with token Token(type=TokenType.ACTION, value='scrape'): Expected '=' after IN POSITION at Token(type=TokenType.SEMICOLON, value=';')\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/exceptions.py</code> <pre><code>class GoatspeakInterpreterException(ScrapegoatCoreException):\n    \"\"\"\n    Exception class for Scrapegoat Goatspeak interpreter-related errors.\n\n    Note:\n        Raised when there is an error interpreting or executing Goatspeak commands. This could be due to syntax, semantic, or runtime issues within the Goatspeak language.\n\n    Example:\n        ```python\n        Shepherd.herd(\"\"VISIT 'https://example.com';SCRAPE p\")\n            GoatspeakInterpreterException: Missing semicolon at the end of the command.\n        ```\n\n    Example:\n        ```python\n        Shepherd.herd(\"VISIT 'https://example.com';SCRAPE p IN POSITION;\")\n            GoatspeakInterpreterException: Error parsing command starting with token Token(type=TokenType.ACTION, value='scrape'): Expected '=' after IN POSITION at Token(type=TokenType.SEMICOLON, value=';')\n        ```\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/classes/block/","title":"Block Classes","text":""},{"location":"core/classes/block/#goatspeakblock-class","title":"GoatspeakBlock Class","text":"<p>A block of goatspeak commands, including a fetch command and a list of queries to be executed on the fetched HTML.</p> Info <p>GoatspeakBlocks group together a fetch command with one or more queries that operate on the fetched HTML content. Each block represents a complete unit of work in a goatspeak script. For example, a GoatspeakBlock may fetch HTML from a URL and then execute several queries to scrape different pieces of data from that HTML. Each query in the block can have its own graze, churn, and deliver commands.</p> <pre><code>print(goatspeak_block.__repr__())\n# Output: GoatspeakBlock(fetch_command=FetchCommand(...), query_list=[Query(...), Query(...)])\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/block.py</code> <pre><code>class GoatspeakBlock:\n    \"\"\"\n    A block of goatspeak commands, including a fetch command and a list of queries to be executed on the fetched HTML.\n\n    Info:\n        GoatspeakBlocks group together a fetch command with one or more queries that operate on the fetched HTML content.\n        Each block represents a complete unit of work in a goatspeak script.\n        For example, a GoatspeakBlock may fetch HTML from a URL and then execute several queries to scrape different pieces of data from that HTML.\n        Each query in the block can have its own graze, churn, and deliver commands.\n\n        ```python\n        print(goatspeak_block.__repr__())\n        # Output: GoatspeakBlock(fetch_command=FetchCommand(...), query_list=[Query(...), Query(...)])\n        ```\n\n    \"\"\"\n    def __init__(self, fetch_command: \"FetchCommand\", query_list: list[\"Query\"]): # type: ignore\n        \"\"\"\n        Initializes the GoatspeakBlock.\n\n        Args:\n            fetch_command (FetchCommand): The command to fetch HTML content.\n            query_list (list): A list of Query objects to be executed on the fetched HTML.\n        \"\"\"\n        self.fetch_command = fetch_command\n        self.query_list = query_list\n\n    def __repr__(self):\n        \"\"\"\n        \"\"\"\n        return f\"GoatspeakBlock(fetch_command={self.fetch_command}, query_list={self.query_list})\"\n</code></pre>"},{"location":"core/classes/block/#scrapegoat_core.classes.block.GoatspeakBlock.__init__","title":"<code>__init__(fetch_command, query_list)</code>","text":"<p>Initializes the GoatspeakBlock.</p> <p>Parameters:</p> Name Type Description Default <code>fetch_command</code> <code>FetchCommand</code> <p>The command to fetch HTML content.</p> required <code>query_list</code> <code>list</code> <p>A list of Query objects to be executed on the fetched HTML.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/block.py</code> <pre><code>def __init__(self, fetch_command: \"FetchCommand\", query_list: list[\"Query\"]): # type: ignore\n    \"\"\"\n    Initializes the GoatspeakBlock.\n\n    Args:\n        fetch_command (FetchCommand): The command to fetch HTML content.\n        query_list (list): A list of Query objects to be executed on the fetched HTML.\n    \"\"\"\n    self.fetch_command = fetch_command\n    self.query_list = query_list\n</code></pre>"},{"location":"core/classes/block/#query-class","title":"Query Class","text":"<p>A query consisting of graze commands to be executed on an HTMLNode tree, along with optional fetch, churn, and deliver commands to control the data flow and representation.</p> Info <p>Queries encapsulate the instructions for scraping data from HTML content. Each Query includes graze commands to select and scrape data, and may also include fetch commands to retrieve HTML, churn commands to extract data, and deliver commands to output results. This structure allows for flexible and modular scraping operations within a goatspeak script.</p> <pre><code>print(query.__repr__())\n# Output: Query(graze_commands=GrazeCommand(...), fetch_command=FetchCommand(...), churn_command=ChurnCommand(...), deliver_command=DeliverCommand(...))\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/block.py</code> <pre><code>class Query:\n    \"\"\"\n    A query consisting of graze commands to be executed on an HTMLNode tree, along with optional fetch, churn, and deliver commands to control the data flow and representation.\n\n    Info:\n        Queries encapsulate the instructions for scraping data from HTML content.\n        Each Query includes graze commands to select and scrape data, and may also include fetch commands to retrieve HTML, churn commands to extract data, and deliver commands to output results.\n        This structure allows for flexible and modular scraping operations within a goatspeak script.\n\n        ```python\n        print(query.__repr__())\n        # Output: Query(graze_commands=GrazeCommand(...), fetch_command=FetchCommand(...), churn_command=ChurnCommand(...), deliver_command=DeliverCommand(...))\n        ```\n    \"\"\"\n    def __init__(self, graze_commands: \"GrazeCommand\", fetch_command: \"FetchCommand\"=None, churn_command:\"ChurnCommand\"=None, deliver_command:\"DeliverCommand\"=None): # type: ignore\n        \"\"\"\n        Initializes the Query.\n\n        Args:\n            graze_commands (GrazeCommand): The graze commands to be executed.\n            fetch_command (FetchCommand): The command to fetch HTML content. Defaults to None.\n            churn_command (ChurnCommand): The command to extract data from scraped nodes. Defaults to None.\n            deliver_command (DeliverCommand): The command to deliver the results. Defaults to None.\n        \"\"\"\n        self.fetch_command = fetch_command\n        self.graze_commands = graze_commands\n        self.churn_command = churn_command\n        self.deliver_command = deliver_command\n\n    def __repr__(self):\n        \"\"\"\n        \"\"\"\n        return f\"Query(graze_commands={self.graze_commands}, fetch_command={self.fetch_command}, churn_command={self.churn_command}, deliver_command={self.deliver_command})\"\n</code></pre>"},{"location":"core/classes/block/#scrapegoat_core.classes.block.Query.__init__","title":"<code>__init__(graze_commands, fetch_command=None, churn_command=None, deliver_command=None)</code>","text":"<p>Initializes the Query.</p> <p>Parameters:</p> Name Type Description Default <code>graze_commands</code> <code>GrazeCommand</code> <p>The graze commands to be executed.</p> required <code>fetch_command</code> <code>FetchCommand</code> <p>The command to fetch HTML content. Defaults to None.</p> <code>None</code> <code>churn_command</code> <code>ChurnCommand</code> <p>The command to extract data from scraped nodes. Defaults to None.</p> <code>None</code> <code>deliver_command</code> <code>DeliverCommand</code> <p>The command to deliver the results. Defaults to None.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/block.py</code> <pre><code>def __init__(self, graze_commands: \"GrazeCommand\", fetch_command: \"FetchCommand\"=None, churn_command:\"ChurnCommand\"=None, deliver_command:\"DeliverCommand\"=None): # type: ignore\n    \"\"\"\n    Initializes the Query.\n\n    Args:\n        graze_commands (GrazeCommand): The graze commands to be executed.\n        fetch_command (FetchCommand): The command to fetch HTML content. Defaults to None.\n        churn_command (ChurnCommand): The command to extract data from scraped nodes. Defaults to None.\n        deliver_command (DeliverCommand): The command to deliver the results. Defaults to None.\n    \"\"\"\n    self.fetch_command = fetch_command\n    self.graze_commands = graze_commands\n    self.churn_command = churn_command\n    self.deliver_command = deliver_command\n</code></pre>"},{"location":"core/classes/commands/","title":"Command Classes","text":""},{"location":"core/classes/commands/#command-base-class","title":"Command (Base Class)","text":"<p>               Bases: <code>ABC</code></p> <p>The base Command class for defining various commands used in goatspeak.</p> Important <p>This is an abstract base class and should not be instantiated directly. Subclasses must implement the execute method to define specific command behaviors.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>class Command(ABC):\n    \"\"\"\n    The base Command class for defining various commands used in goatspeak.\n\n    Important:\n        This is an abstract base class and should not be instantiated directly.\n        Subclasses must implement the execute method to define specific command behaviors.\n    \"\"\"\n    @abstractmethod\n    def __init__(self, action: str):\n        \"\"\"\n        Initializes the Command.\n\n        Args:\n            action (str): The action type of the command.\n        \"\"\"\n        self.action = action\n\n    @abstractmethod\n    def execute(self, root: \"HTMLNode\") -&gt; any: # type: ignore\n        \"\"\"\n        Executes the command.\n\n        Args:\n            root: The root HTMLNode on which to execute the command.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.Command.__init__","title":"<code>__init__(action)</code>  <code>abstractmethod</code>","text":"<p>Initializes the Command.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>str</code> <p>The action type of the command.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>@abstractmethod\ndef __init__(self, action: str):\n    \"\"\"\n    Initializes the Command.\n\n    Args:\n        action (str): The action type of the command.\n    \"\"\"\n    self.action = action\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.Command.execute","title":"<code>execute(root)</code>  <code>abstractmethod</code>","text":"<p>Executes the command.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>HTMLNode</code> <p>The root HTMLNode on which to execute the command.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>@abstractmethod\ndef execute(self, root: \"HTMLNode\") -&gt; any: # type: ignore\n    \"\"\"\n    Executes the command.\n\n    Args:\n        root: The root HTMLNode on which to execute the command.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/classes/commands/#commands","title":"Commands","text":""},{"location":"core/classes/commands/#grazecommand","title":"GrazeCommand","text":"<p>               Bases: <code>Command</code></p> <p>The GrazeCommand class for defining commands to parse HTMLNodes from tree structures.</p> Info <p>A GrazeCommand can either be a select, which rebases the root node for subsequent commands, or a scrape, which extracts the entire set of matching nodes. GrazeCommands can also include conditions to filter the nodes they operate on. All conditions must be met for a node to be selected by a GrazeCommand.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>class GrazeCommand(Command):\n    \"\"\"\n    The GrazeCommand class for defining commands to parse HTMLNodes from tree structures.\n\n    Info:\n        A GrazeCommand can either be a select, which rebases the root node for subsequent commands, or a scrape, which extracts the entire set of matching nodes.\n        GrazeCommands can also include conditions to filter the nodes they operate on.\n        All conditions must be met for a node to be selected by a GrazeCommand.\n    \"\"\"\n    def __init__(self, action: str, count: int, element: str, conditions: list[\"Condition\"]=None, flags: list=None): # type: ignore\n        \"\"\"\n        Initializes the GrazeCommand.\n\n        Args:\n            action (str): The action type of the command (\"select\" or \"scrape\").\n            count (int): The maximum number of elements to return. Use 0 for no limit.\n            element (str): The HTML tag to target.\n            conditions (list, optional): A list of Condition objects to filter the nodes. Defaults to None.\n            flags (list, optional): A list of flags to modify command behavior. Defaults to None.\n        \"\"\"\n        super().__init__(action=action)\n        self.count = count\n        self.element = element\n        self.conditions = conditions or []\n        self.flags = flags or []\n\n        for cond in self.conditions:\n            if isinstance(cond, InCondition) and cond.target == \"POSITION\" and cond.query_tag is None:\n                cond.query_tag = self.element\n\n    def _evaluate(self, node, root) -&gt; bool:\n        \"\"\"\n        \"\"\"\n        if node.tag_type != self.element:\n            return False\n        return all(cond.evaluate(node, root) for cond in self.conditions)\n\n    def execute(self, root: \"HTMLNode\") -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Executes the GrazeCommand on the given root HTMLNode.\n\n        Args:\n            root (HTMLNode): The root HTMLNode from which to execute the command.\n\n        Returns:\n            list: A list of HTMLNode objects that match the command criteria.\n        \"\"\"\n        results = []\n        for node in root.preorder_traversal():\n            if self._evaluate(node, root):\n                results.append(node)\n                if self.count &gt; 0 and len(results) &gt;= self.count:\n                    break\n        return results\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.GrazeCommand.__init__","title":"<code>__init__(action, count, element, conditions=None, flags=None)</code>","text":"<p>Initializes the GrazeCommand.</p> <p>Parameters:</p> Name Type Description Default <code>action</code> <code>str</code> <p>The action type of the command (\"select\" or \"scrape\").</p> required <code>count</code> <code>int</code> <p>The maximum number of elements to return. Use 0 for no limit.</p> required <code>element</code> <code>str</code> <p>The HTML tag to target.</p> required <code>conditions</code> <code>list</code> <p>A list of Condition objects to filter the nodes. Defaults to None.</p> <code>None</code> <code>flags</code> <code>list</code> <p>A list of flags to modify command behavior. Defaults to None.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def __init__(self, action: str, count: int, element: str, conditions: list[\"Condition\"]=None, flags: list=None): # type: ignore\n    \"\"\"\n    Initializes the GrazeCommand.\n\n    Args:\n        action (str): The action type of the command (\"select\" or \"scrape\").\n        count (int): The maximum number of elements to return. Use 0 for no limit.\n        element (str): The HTML tag to target.\n        conditions (list, optional): A list of Condition objects to filter the nodes. Defaults to None.\n        flags (list, optional): A list of flags to modify command behavior. Defaults to None.\n    \"\"\"\n    super().__init__(action=action)\n    self.count = count\n    self.element = element\n    self.conditions = conditions or []\n    self.flags = flags or []\n\n    for cond in self.conditions:\n        if isinstance(cond, InCondition) and cond.target == \"POSITION\" and cond.query_tag is None:\n            cond.query_tag = self.element\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.GrazeCommand.execute","title":"<code>execute(root)</code>","text":"<p>Executes the GrazeCommand on the given root HTMLNode.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>HTMLNode</code> <p>The root HTMLNode from which to execute the command.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[HTMLNode]</code> <p>A list of HTMLNode objects that match the command criteria.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def execute(self, root: \"HTMLNode\") -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Executes the GrazeCommand on the given root HTMLNode.\n\n    Args:\n        root (HTMLNode): The root HTMLNode from which to execute the command.\n\n    Returns:\n        list: A list of HTMLNode objects that match the command criteria.\n    \"\"\"\n    results = []\n    for node in root.preorder_traversal():\n        if self._evaluate(node, root):\n            results.append(node)\n            if self.count &gt; 0 and len(results) &gt;= self.count:\n                break\n    return results\n</code></pre>"},{"location":"core/classes/commands/#churncommand","title":"ChurnCommand","text":"<p>               Bases: <code>Command</code></p> <p>The ChurnCommand class for defining how an HTMLNode is to be represented after being scraped.</p> Info <p>This command is used to extract specific data from the scraped nodes. To do this, the ChurnCommand takes in a list of fields to extract, as well as flags to ignore children or grandchildren nodes during extraction. If scraping a table, the table flag can be set to True to represent the table as it would appear on a webpage.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>class ChurnCommand(Command):\n    \"\"\"\n    The ChurnCommand class for defining how an HTMLNode is to be represented after being scraped.\n\n    Info:\n        This command is used to extract specific data from the scraped nodes.\n        To do this, the ChurnCommand takes in a list of fields to extract, as well as flags to ignore children or grandchildren nodes during extraction.\n        If scraping a table, the table flag can be set to True to represent the table as it would appear on a webpage.\n    \"\"\"\n    def __init__(self, fields: list[str] = None, ignore_children: bool = False, ignore_grandchildren: bool = False, table: bool = False):\n        \"\"\"\n        Initializes the ChurnCommand.\n\n        Args:\n            fields (list, optional): A list of fields to extract from the node. Defaults to None.\n            ignore_children (bool, optional): Whether to ignore child nodes during extraction. Defaults to False.\n            ignore_grandchildren (bool, optional): Whether to ignore grandchild nodes during extraction. Defaults to False.\n            table (bool, optional): Whether to represent the node as a table. Defaults to False.\n        \"\"\"\n        super().__init__(action=\"extract\")\n        self.fields = fields\n        self.ignore_children = ignore_children\n        self.ignore_grandchildren = ignore_grandchildren\n        self.table = table\n\n    def execute(self, node: \"HTMLNode\") -&gt; None: # type: ignore\n        \"\"\"\n        Executes the ChurnCommand on the given HTMLNode.\n\n        Args:\n            node (HTMLNode): The HTMLNode to extract data from.\n        \"\"\"\n        node.set_extract_instructions(self.fields, self.ignore_children, self.ignore_grandchildren, self.table)\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.ChurnCommand.__init__","title":"<code>__init__(fields=None, ignore_children=False, ignore_grandchildren=False, table=False)</code>","text":"<p>Initializes the ChurnCommand.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>list</code> <p>A list of fields to extract from the node. Defaults to None.</p> <code>None</code> <code>ignore_children</code> <code>bool</code> <p>Whether to ignore child nodes during extraction. Defaults to False.</p> <code>False</code> <code>ignore_grandchildren</code> <code>bool</code> <p>Whether to ignore grandchild nodes during extraction. Defaults to False.</p> <code>False</code> <code>table</code> <code>bool</code> <p>Whether to represent the node as a table. Defaults to False.</p> <code>False</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def __init__(self, fields: list[str] = None, ignore_children: bool = False, ignore_grandchildren: bool = False, table: bool = False):\n    \"\"\"\n    Initializes the ChurnCommand.\n\n    Args:\n        fields (list, optional): A list of fields to extract from the node. Defaults to None.\n        ignore_children (bool, optional): Whether to ignore child nodes during extraction. Defaults to False.\n        ignore_grandchildren (bool, optional): Whether to ignore grandchild nodes during extraction. Defaults to False.\n        table (bool, optional): Whether to represent the node as a table. Defaults to False.\n    \"\"\"\n    super().__init__(action=\"extract\")\n    self.fields = fields\n    self.ignore_children = ignore_children\n    self.ignore_grandchildren = ignore_grandchildren\n    self.table = table\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.ChurnCommand.execute","title":"<code>execute(node)</code>","text":"<p>Executes the ChurnCommand on the given HTMLNode.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>HTMLNode</code> <p>The HTMLNode to extract data from.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def execute(self, node: \"HTMLNode\") -&gt; None: # type: ignore\n    \"\"\"\n    Executes the ChurnCommand on the given HTMLNode.\n\n    Args:\n        node (HTMLNode): The HTMLNode to extract data from.\n    \"\"\"\n    node.set_extract_instructions(self.fields, self.ignore_children, self.ignore_grandchildren, self.table)\n</code></pre>"},{"location":"core/classes/commands/#delivercommand","title":"DeliverCommand","text":"<p>               Bases: <code>Command</code></p> <p>The DeliverCommand class for defining how scraped HTMLNode results are to be exported to a file.</p> Info <p>The DeliverCommand currently only supports exports to CSV and JSON file formats. By default, if no filepath is provided, the file will be saved in the current working directory. If no filename is provided, a default name of \"output\" with the appropriate file extension will be used.</p> <p>Attributes:</p> Name Type Description <code>VALID_TYPES</code> <code>set</code> <p>A set of valid file types for delivery (\"csv\", \"json\").</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>class DeliverCommand(Command):\n    \"\"\"\n    The DeliverCommand class for defining how scraped HTMLNode results are to be exported to a file.\n\n    Info:\n        The DeliverCommand currently only supports exports to CSV and JSON file formats.\n        By default, if no filepath is provided, the file will be saved in the current working directory.\n        If no filename is provided, a default name of \"output\" with the appropriate file extension will be used.\n\n    Attributes:\n        VALID_TYPES (set): A set of valid file types for delivery (\"csv\", \"json\").\n    \"\"\"\n    VALID_TYPES = {\"csv\", \"json\"}\n\n    def __init__(self, file_type: str, filepath: str = None, filename: str = None):\n        \"\"\"\n        Initializes the DeliverCommand.\n\n        Args:\n            file_type (str): The type of file to deliver the results to (\"csv\" or \"json\").\n            filepath (str, optional): The directory path where the file will be saved. Defaults to the current working directory.\n            filename (str, optional): The name of the file. If not provided, a default name will be used. Defaults to None.\n        \"\"\"\n        super().__init__(action=\"output\")\n        self.file_type = file_type\n        self.filepath = filepath or os.getcwd()\n        base, ext = os.path.splitext(filename or f\"output.{file_type}\")\n        self.filename = base + (ext if ext else f\".{file_type}\")\n        self.full_path = os.path.join(self.filepath, self.filename)\n\n    def execute(self, nodes: list[\"HTMLNode\"]) -&gt; str: # type: ignore\n        \"\"\"\n        Executes the DeliverCommand to save the scraped HTMLNode results to a file.\n\n        Args:\n            nodes (list): A list of scraped HTMLNode results.\n\n        Returns:\n            str: The full path to the saved file.\n        \"\"\"\n        os.makedirs(self.filepath, exist_ok=True)\n\n        if self.file_type.lower() == \"csv\":\n            self._to_csv(nodes)\n        elif self.file_type.lower() == \"json\":\n            self._to_json(nodes)\n        return self.full_path\n\n    def _flatten_dict(self, d: dict, parent_key: str = '', sep: str = '.') -&gt; dict:\n        \"\"\"\n        \"\"\"\n        items = {}\n        for k, v in d.items():\n            new_key = f\"{k}\" if parent_key else k\n            if isinstance(v, dict):\n                items.update(self._flatten_dict(v, new_key, sep=sep))\n            else:\n                items[new_key] = v\n        return items\n\n    def _collect_nodes(self, node_dict: dict, all_nodes: list) -&gt; dict:\n        \"\"\"\n        \"\"\"\n        if type(node_dict) is not dict:\n            for item in node_dict:\n                self._collect_nodes(item, all_nodes)\n            return\n        node_copy = node_dict.copy()\n\n        had_children = \"children\" in node_copy\n        children = node_copy.pop(\"children\", [])\n        child_ids = []\n\n        for child in children:\n            child_flat = self._collect_nodes(child, all_nodes)\n            child_ids.append(child_flat.get(\"id\"))\n\n        flattened = self._flatten_dict(node_copy)\n        if had_children:\n            if child_ids == [] or all(cid is None for cid in child_ids):\n                flattened[\"children\"] = None\n            else:\n                flattened[\"children\"] = child_ids\n\n        all_nodes.append(flattened)\n        return node_copy\n\n    def _to_csv(self, nodes: list) -&gt; None:\n        \"\"\"\n        \"\"\"\n        all_nodes = []\n        for node in nodes:\n            # check if node is a list:\n            node_dict = node.to_dict()\n            self._collect_nodes(node_dict, all_nodes)\n\n        fieldnames = set()\n        for nd in all_nodes:\n            fieldnames.update(nd.keys())\n        fieldnames = list(fieldnames)\n\n        os.makedirs(self.filepath, exist_ok=True)\n        with open(self.full_path, mode='w', newline='', encoding='utf-8') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            writer.writeheader()\n            for nd in all_nodes:\n                writer.writerow(nd)\n\n    def _to_json(self, nodes: list) -&gt; None:\n        \"\"\"\n        \"\"\"\n        nodes_as_dicts = [node.to_dict() for node in nodes]\n        with open(self.full_path, mode='w', encoding='utf-8') as jsonfile:\n            json.dump(nodes_as_dicts, jsonfile, indent=4)\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.DeliverCommand.__init__","title":"<code>__init__(file_type, filepath=None, filename=None)</code>","text":"<p>Initializes the DeliverCommand.</p> <p>Parameters:</p> Name Type Description Default <code>file_type</code> <code>str</code> <p>The type of file to deliver the results to (\"csv\" or \"json\").</p> required <code>filepath</code> <code>str</code> <p>The directory path where the file will be saved. Defaults to the current working directory.</p> <code>None</code> <code>filename</code> <code>str</code> <p>The name of the file. If not provided, a default name will be used. Defaults to None.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def __init__(self, file_type: str, filepath: str = None, filename: str = None):\n    \"\"\"\n    Initializes the DeliverCommand.\n\n    Args:\n        file_type (str): The type of file to deliver the results to (\"csv\" or \"json\").\n        filepath (str, optional): The directory path where the file will be saved. Defaults to the current working directory.\n        filename (str, optional): The name of the file. If not provided, a default name will be used. Defaults to None.\n    \"\"\"\n    super().__init__(action=\"output\")\n    self.file_type = file_type\n    self.filepath = filepath or os.getcwd()\n    base, ext = os.path.splitext(filename or f\"output.{file_type}\")\n    self.filename = base + (ext if ext else f\".{file_type}\")\n    self.full_path = os.path.join(self.filepath, self.filename)\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.DeliverCommand.execute","title":"<code>execute(nodes)</code>","text":"<p>Executes the DeliverCommand to save the scraped HTMLNode results to a file.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>A list of scraped HTMLNode results.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The full path to the saved file.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def execute(self, nodes: list[\"HTMLNode\"]) -&gt; str: # type: ignore\n    \"\"\"\n    Executes the DeliverCommand to save the scraped HTMLNode results to a file.\n\n    Args:\n        nodes (list): A list of scraped HTMLNode results.\n\n    Returns:\n        str: The full path to the saved file.\n    \"\"\"\n    os.makedirs(self.filepath, exist_ok=True)\n\n    if self.file_type.lower() == \"csv\":\n        self._to_csv(nodes)\n    elif self.file_type.lower() == \"json\":\n        self._to_json(nodes)\n    return self.full_path\n</code></pre>"},{"location":"core/classes/commands/#fetchcommand","title":"FetchCommand","text":"<p>               Bases: <code>Command</code></p> <p>The FetchCommand class executes the getter function from its attributes to retrieve HTML content from a specified URL.</p> Info <p>By default, the FetchCommand uses the requests.get method, but this can be overridden by providing a custom getter function. Through the Sheepdog class, the getter can be easily overwritten, either by passing in a custom function or by extending the Sheepdog class itself, with a new implementation of the getter method.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>class FetchCommand(Command):\n    \"\"\"\n    The FetchCommand class executes the getter function from its attributes to retrieve HTML content from a specified URL.\n\n    Info:\n        By default, the FetchCommand uses the requests.get method, but this can be overridden by providing a custom getter function.\n        Through the Sheepdog class, the getter can be easily overwritten, either by passing in a custom function or by extending the Sheepdog class itself, with a new implementation of the getter method.\n    \"\"\"\n    def __init__(self, url: str, **kwargs):\n        \"\"\"\n        Initializes the FetchCommand.\n\n        Args:\n            url (str): The URL to fetch HTML content from.\n            **kwargs: Additional keyword arguments to pass to the getter function.\n        \"\"\"\n        super().__init__(action=\"visit\")\n        self.getter = requests.get\n        self.url = url\n        self.kwargs = kwargs\n\n    def execute(self) -&gt; str:\n        \"\"\"\n        Executes the FetchCommand to retrieve HTML content from the specified URL.\n\n        Returns:\n            str: The fetched HTML content.\n        \"\"\"\n        return self.getter(self.url, **self.kwargs)\n\n    def set_getter(self, getter: callable) -&gt; None:\n        \"\"\"\n        Sets a custom getter function for fetching HTML content.\n\n        Args:\n            getter (callable): A custom function that takes a URL and returns HTML content.\n        \"\"\"\n        self.getter = getter\n\n    def __eq__(self, other):\n        \"\"\"\n        \"\"\"\n        return isinstance(other, FetchCommand) and self.url == other.url\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.FetchCommand.__init__","title":"<code>__init__(url, **kwargs)</code>","text":"<p>Initializes the FetchCommand.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to fetch HTML content from.</p> required <code>**kwargs</code> <p>Additional keyword arguments to pass to the getter function.</p> <code>{}</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def __init__(self, url: str, **kwargs):\n    \"\"\"\n    Initializes the FetchCommand.\n\n    Args:\n        url (str): The URL to fetch HTML content from.\n        **kwargs: Additional keyword arguments to pass to the getter function.\n    \"\"\"\n    super().__init__(action=\"visit\")\n    self.getter = requests.get\n    self.url = url\n    self.kwargs = kwargs\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.FetchCommand.execute","title":"<code>execute()</code>","text":"<p>Executes the FetchCommand to retrieve HTML content from the specified URL.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The fetched HTML content.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def execute(self) -&gt; str:\n    \"\"\"\n    Executes the FetchCommand to retrieve HTML content from the specified URL.\n\n    Returns:\n        str: The fetched HTML content.\n    \"\"\"\n    return self.getter(self.url, **self.kwargs)\n</code></pre>"},{"location":"core/classes/commands/#scrapegoat_core.classes.command.FetchCommand.set_getter","title":"<code>set_getter(getter)</code>","text":"<p>Sets a custom getter function for fetching HTML content.</p> <p>Parameters:</p> Name Type Description Default <code>getter</code> <code>callable</code> <p>A custom function that takes a URL and returns HTML content.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/command.py</code> <pre><code>def set_getter(self, getter: callable) -&gt; None:\n    \"\"\"\n    Sets a custom getter function for fetching HTML content.\n\n    Args:\n        getter (callable): A custom function that takes a URL and returns HTML content.\n    \"\"\"\n    self.getter = getter\n</code></pre>"},{"location":"core/classes/conditions/","title":"Condition Classes","text":""},{"location":"core/classes/conditions/#condition-base-class","title":"Condition (Base Class)","text":"<p>               Bases: <code>ABC</code></p> <p>The base Condition class for defining conditions used in scrape and select commands.</p> Important <p>This is an abstract base class and cannot be instantiated directly. Subclasses must implement the <code>matches</code> method to define specific condition logic.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>class Condition(ABC):\n    \"\"\"\n    The base Condition class for defining conditions used in scrape and select commands.\n\n    Important:\n        This is an abstract base class and cannot be instantiated directly.\n        Subclasses must implement the `matches` method to define specific condition logic.\n    \"\"\"\n    def __init__(self, negated: bool = False):\n        \"\"\"\n        Initializes the Condition.\n\n        Args:\n            negated (bool): Whether the condition is negated. Defaults to False.\n        \"\"\"\n        self.negated = negated\n\n    @abstractmethod\n    def matches(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n        \"\"\"\n        Determines if the condition matches the given node.\n        Must be implemented by subclasses.\n\n        Args:\n            node (HTMLNode): The HTMLNode to evaluate the condition against.\n            root (HTMLNode): The root HTMLNode of the tree.\n\n        Returns:\n            bool: True if the condition matches, False otherwise.\n        \"\"\"\n        pass\n\n    def evaluate(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n        \"\"\"\n        Evaluates the condition against the given node, taking into account negation.\n\n        Args:\n            node (HTMLNode): The HTMLNode to evaluate the condition against.\n            root (HTMLNode): The root HTMLNode of the tree.\n\n        Returns:\n            bool: The result of the condition evaluation, considering negation.\n        \"\"\"\n        result = self.matches(node, root)\n        return not result if self.negated else result\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.Condition.__init__","title":"<code>__init__(negated=False)</code>","text":"<p>Initializes the Condition.</p> <p>Parameters:</p> Name Type Description Default <code>negated</code> <code>bool</code> <p>Whether the condition is negated. Defaults to False.</p> <code>False</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def __init__(self, negated: bool = False):\n    \"\"\"\n    Initializes the Condition.\n\n    Args:\n        negated (bool): Whether the condition is negated. Defaults to False.\n    \"\"\"\n    self.negated = negated\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.Condition.evaluate","title":"<code>evaluate(node, root)</code>","text":"<p>Evaluates the condition against the given node, taking into account negation.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>HTMLNode</code> <p>The HTMLNode to evaluate the condition against.</p> required <code>root</code> <code>HTMLNode</code> <p>The root HTMLNode of the tree.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The result of the condition evaluation, considering negation.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def evaluate(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n    \"\"\"\n    Evaluates the condition against the given node, taking into account negation.\n\n    Args:\n        node (HTMLNode): The HTMLNode to evaluate the condition against.\n        root (HTMLNode): The root HTMLNode of the tree.\n\n    Returns:\n        bool: The result of the condition evaluation, considering negation.\n    \"\"\"\n    result = self.matches(node, root)\n    return not result if self.negated else result\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.Condition.matches","title":"<code>matches(node, root)</code>  <code>abstractmethod</code>","text":"<p>Determines if the condition matches the given node. Must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>HTMLNode</code> <p>The HTMLNode to evaluate the condition against.</p> required <code>root</code> <code>HTMLNode</code> <p>The root HTMLNode of the tree.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the condition matches, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>@abstractmethod\ndef matches(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n    \"\"\"\n    Determines if the condition matches the given node.\n    Must be implemented by subclasses.\n\n    Args:\n        node (HTMLNode): The HTMLNode to evaluate the condition against.\n        root (HTMLNode): The root HTMLNode of the tree.\n\n    Returns:\n        bool: True if the condition matches, False otherwise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/classes/conditions/#conditions","title":"Conditions","text":""},{"location":"core/classes/conditions/#ifcondition","title":"IfCondition","text":"<p>               Bases: <code>Condition</code></p> <p>The IfCondition class for defining attribute-based conditions used in scrape and select commands.</p> Info <p>Supports both exact and like matching. Returns true if the specified attribute matches the given value or if the specified attribute is present when no value is provided.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>class IfCondition(Condition):\n    \"\"\"\n    The IfCondition class for defining attribute-based conditions used in scrape and select commands.\n\n    Info:\n        Supports both exact and like matching.\n        Returns true if the specified attribute matches the given value or if the specified attribute is present when no value is provided.\n    \"\"\"\n    def __init__(self, key: str, value: str, negated: bool = False, query_tag: str = None, like: bool = False):\n        \"\"\"\n        Initializes the IfCondition.\n\n        Args:\n            key (str): The attribute key to check. Prefix with \"@\" for HTML attributes.\n            value (str): The attribute value to match.\n            negated (bool): Whether the condition is negated. Defaults to False.\n            query_tag (str): The HTML tag to which the condition applies. If None, applies to all tags. Defaults to None.\n            like (bool): Whether to use like matching (True) or exact matching (False). Defaults to False.\n        \"\"\"\n        super().__init__(negated)\n        self.key = key\n        self.value = value\n        self.query_tag = query_tag\n        self.like = like\n\n    def matches(self, node: \"HTMLNode\", _:\"HTMLNode\"=None) -&gt; bool: # type: ignore\n        \"\"\"\n        Determines if the condition matches the given node.\n\n        Args:\n            node (HTMLNode): The HTMLNode to evaluate the condition against.\n            _ (HTMLNode): The root HTMLNode of the tree (not used in this condition). Defaults to None.\n\n        Returns:\n            bool: True if the condition matches, False otherwise.\n        \"\"\"\n        if self.query_tag is None:\n            raise ScrapegoatMissingFieldException(\"query_tag must be specified for IfCondition\")\n        if self.like:\n            return self._like_match(node)\n        else:\n            return self._exact_match(node)\n\n    def _like_match(self, node) -&gt; bool:\n        \"\"\"\n        \"\"\"\n        if self.key[0] == \"@\":\n            return node.like_html_attribute(self.key, self.value) and node.tag_type == self.query_tag\n        else:\n            return node.like_attribute(self.key, self.value) and node.tag_type == self.query_tag\n\n    def _exact_match(self, node) -&gt; bool:\n        \"\"\"\n        \"\"\"\n        if self.key[0] == \"@\":\n            return node.has_html_attribute(self.key, self.value) and node.tag_type == self.query_tag\n        else:\n            return node.has_attribute(self.key, self.value) and node.tag_type == self.query_tag\n\n    def __str__(self):\n        \"\"\"\n        \"\"\"\n        return f\"IfCondition(key={self.key}, value={self.value}, negated={self.negated}, query_tag={self.query_tag})\"\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.IfCondition.__init__","title":"<code>__init__(key, value, negated=False, query_tag=None, like=False)</code>","text":"<p>Initializes the IfCondition.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The attribute key to check. Prefix with \"@\" for HTML attributes.</p> required <code>value</code> <code>str</code> <p>The attribute value to match.</p> required <code>negated</code> <code>bool</code> <p>Whether the condition is negated. Defaults to False.</p> <code>False</code> <code>query_tag</code> <code>str</code> <p>The HTML tag to which the condition applies. If None, applies to all tags. Defaults to None.</p> <code>None</code> <code>like</code> <code>bool</code> <p>Whether to use like matching (True) or exact matching (False). Defaults to False.</p> <code>False</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def __init__(self, key: str, value: str, negated: bool = False, query_tag: str = None, like: bool = False):\n    \"\"\"\n    Initializes the IfCondition.\n\n    Args:\n        key (str): The attribute key to check. Prefix with \"@\" for HTML attributes.\n        value (str): The attribute value to match.\n        negated (bool): Whether the condition is negated. Defaults to False.\n        query_tag (str): The HTML tag to which the condition applies. If None, applies to all tags. Defaults to None.\n        like (bool): Whether to use like matching (True) or exact matching (False). Defaults to False.\n    \"\"\"\n    super().__init__(negated)\n    self.key = key\n    self.value = value\n    self.query_tag = query_tag\n    self.like = like\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.IfCondition.matches","title":"<code>matches(node, _=None)</code>","text":"<p>Determines if the condition matches the given node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>HTMLNode</code> <p>The HTMLNode to evaluate the condition against.</p> required <code>_</code> <code>HTMLNode</code> <p>The root HTMLNode of the tree (not used in this condition). Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the condition matches, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def matches(self, node: \"HTMLNode\", _:\"HTMLNode\"=None) -&gt; bool: # type: ignore\n    \"\"\"\n    Determines if the condition matches the given node.\n\n    Args:\n        node (HTMLNode): The HTMLNode to evaluate the condition against.\n        _ (HTMLNode): The root HTMLNode of the tree (not used in this condition). Defaults to None.\n\n    Returns:\n        bool: True if the condition matches, False otherwise.\n    \"\"\"\n    if self.query_tag is None:\n        raise ScrapegoatMissingFieldException(\"query_tag must be specified for IfCondition\")\n    if self.like:\n        return self._like_match(node)\n    else:\n        return self._exact_match(node)\n</code></pre>"},{"location":"core/classes/conditions/#incondition","title":"InCondition","text":"<p>               Bases: <code>Condition</code></p> <p>The InCondition class for defining hierarchical conditions used in scrape and select commands.</p> Info <p>Supports checking if a node is a descendant of a target tag or if it is at a specific position relative to the entire tree with respect to elements of the same tag.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>class InCondition(Condition):\n    \"\"\"\n    The InCondition class for defining hierarchical conditions used in scrape and select commands.\n\n    Info:\n        Supports checking if a node is a descendant of a target tag or if it is at a specific position relative to the entire tree with respect to elements of the same tag.\n    \"\"\"\n    def __init__(self, target: str, value=None, negated: bool = False, query_tag: str = None):\n        \"\"\"\n        Initializes the InCondition.\n\n        Args:\n            target (str): The target tag to check against or \"POSITION\" for position-based checks\n            value (int): The position value to match when target is \"POSITION\". Defaults to None.\n            negated (bool): Whether the condition is negated. Defaults to False.\n            query_tag (str): The HTML tag to which the position condition applies. Required if target is \"POSITION\". Defaults to None.\n        \"\"\"\n        super().__init__(negated)\n        self.target = target\n        self.value = value\n        self.query_tag = query_tag\n\n    def matches(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n        \"\"\"\n        Determines if the condition matches the given node.\n\n        Args:\n            node (HTMLNode): The HTMLNode to evaluate the condition against.\n            root (HTMLNode): The root HTMLNode of the tree.\n\n        Returns:\n            bool: True if the condition matches, False otherwise.\n        \"\"\"\n        if self.target == \"POSITION\":\n            if not root:\n                raise ScrapegoatMissingFieldException(\"root is required for POSITION condition\")\n            if not self.query_tag:\n                raise ScrapegoatMissingFieldException(\"query_tag is required for POSITION condition\")\n            position = 1\n            for n in root.preorder_traversal():\n                if n.tag_type == self.query_tag:\n                    if node == n:\n                        return position == self.value\n                    position += 1\n            return False\n        else:\n            return node.is_descendant_of(self.target)\n\n    def __str__(self):\n        \"\"\"\n        \"\"\"\n        return f\"InCondition(target={self.target}, value={self.value}, negated={self.negated}, query_tag={self.query_tag})\"\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.InCondition.__init__","title":"<code>__init__(target, value=None, negated=False, query_tag=None)</code>","text":"<p>Initializes the InCondition.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The target tag to check against or \"POSITION\" for position-based checks</p> required <code>value</code> <code>int</code> <p>The position value to match when target is \"POSITION\". Defaults to None.</p> <code>None</code> <code>negated</code> <code>bool</code> <p>Whether the condition is negated. Defaults to False.</p> <code>False</code> <code>query_tag</code> <code>str</code> <p>The HTML tag to which the position condition applies. Required if target is \"POSITION\". Defaults to None.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def __init__(self, target: str, value=None, negated: bool = False, query_tag: str = None):\n    \"\"\"\n    Initializes the InCondition.\n\n    Args:\n        target (str): The target tag to check against or \"POSITION\" for position-based checks\n        value (int): The position value to match when target is \"POSITION\". Defaults to None.\n        negated (bool): Whether the condition is negated. Defaults to False.\n        query_tag (str): The HTML tag to which the position condition applies. Required if target is \"POSITION\". Defaults to None.\n    \"\"\"\n    super().__init__(negated)\n    self.target = target\n    self.value = value\n    self.query_tag = query_tag\n</code></pre>"},{"location":"core/classes/conditions/#scrapegoat_core.classes.conditions.InCondition.matches","title":"<code>matches(node, root)</code>","text":"<p>Determines if the condition matches the given node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>HTMLNode</code> <p>The HTMLNode to evaluate the condition against.</p> required <code>root</code> <code>HTMLNode</code> <p>The root HTMLNode of the tree.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the condition matches, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/conditions.py</code> <pre><code>def matches(self, node: \"HTMLNode\", root: \"HTMLNode\") -&gt; bool: # type: ignore\n    \"\"\"\n    Determines if the condition matches the given node.\n\n    Args:\n        node (HTMLNode): The HTMLNode to evaluate the condition against.\n        root (HTMLNode): The root HTMLNode of the tree.\n\n    Returns:\n        bool: True if the condition matches, False otherwise.\n    \"\"\"\n    if self.target == \"POSITION\":\n        if not root:\n            raise ScrapegoatMissingFieldException(\"root is required for POSITION condition\")\n        if not self.query_tag:\n            raise ScrapegoatMissingFieldException(\"query_tag is required for POSITION condition\")\n        position = 1\n        for n in root.preorder_traversal():\n            if n.tag_type == self.query_tag:\n                if node == n:\n                    return position == self.value\n                position += 1\n        return False\n    else:\n        return node.is_descendant_of(self.target)\n</code></pre>"},{"location":"core/classes/gardener/","title":"Gardener Class","text":""},{"location":"core/classes/gardener/#gardener","title":"Gardener","text":"<p>               Bases: <code>HTMLParser</code></p> <p>The Gardener class is responsible for parsing raw HTML into a tree structure composed of HTMLNodes.</p> Info <p>Under the hood, the Gardener class extends Python's built-in HTMLParser to handle HTML tags, attributes, and text content. When an inline tag is encountered, its text content is bubbled up to its parent node to ensure proper representation of text as it would appear on the DOM.</p> <p>Attributes:</p> Name Type Description <code>VOID_TAGS</code> <code>set</code> <p>A set of HTML tags that do not require closing tags.</p> <code>AUTO_CLOSE</code> <code>dict</code> <p>A mapping of tags to sets of tags that should trigger auto-closing of the current tag.</p> <code>INLINE_TAGS</code> <code>set</code> <p>A set of HTML tags that are considered inline elements.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/gardener.py</code> <pre><code>class Gardener(HTMLParser):\n    \"\"\"\n    The Gardener class is responsible for parsing raw HTML into a tree structure composed of HTMLNodes.\n\n    Info:\n        Under the hood, the Gardener class extends Python's built-in HTMLParser to handle HTML tags, attributes, and text content.\n        When an inline tag is encountered, its text content is bubbled up to its parent node to ensure proper representation of text as it would appear on the DOM.\n\n    Attributes:\n        VOID_TAGS (set): A set of HTML tags that do not require closing tags.\n        AUTO_CLOSE (dict): A mapping of tags to sets of tags that should trigger auto-closing of the current tag.\n        INLINE_TAGS (set): A set of HTML tags that are considered inline elements.\n    \"\"\"\n    VOID_TAGS = {\"area\", \"base\", \"br\", \"col\", \"embed\", \"hr\", \"img\", \"input\", \"link\", \"meta\", \"param\", \"source\", \"track\", \"wbr\"}\n    AUTO_CLOSE = {\n        \"li\": {\"li\"},\n        \"p\": {\"address\", \"article\", \"aside\", \"blockquote\", \"div\", \"dl\", \"fieldset\", \"footer\", \"form\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"header\", \"hgroup\", \"hr\", \"main\", \"nav\", \"ol\", \"p\", \"pre\", \"section\", \"table\", \"ul\"},\n        \"dt\": {\"dt\", \"dd\"},\n        \"dd\": {\"dt\", \"dd\"},\n        \"tr\": {\"tr\"},\n        \"td\": {\"td\", \"th\"},\n        \"th\": {\"td\", \"th\"}\n    }\n    INLINE_TAGS = {\"b\", \"i\", \"strong\", \"em\", \"u\", \"small\", \"mark\", \"sub\", \"sup\", \"a\", \"span\", \"img\", \"br\", \"code\", \"s\", \"q\", \"cite\"}\n\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the Gardener class.\n        \"\"\"\n        super().__init__()\n        self.tag_counts = {}\n        self.root = None\n        self.stack = []\n\n    def _auto_close_before(self, new_tag: str):\n        \"\"\"\n        \"\"\"\n        while self.stack:\n            current_node = next((n for n in reversed(self.stack) if n is not None), None)\n            if current_node is None:\n                break\n\n            current_tag = current_node.tag_type\n            if current_tag in self.AUTO_CLOSE and new_tag in self.AUTO_CLOSE[current_tag]:\n                while self.stack:\n                    popped = self.stack.pop()\n                    if popped is current_node:\n                        break\n            else:\n                break\n\n    def handle_starttag(self, tag_type: str, html_attributes: list[tuple[str, str]]) -&gt; None:\n        \"\"\"\n        \"\"\"\n        self._auto_close_before(tag_type)\n\n        node = HTMLNode(raw=self.get_starttag_text(), tag_type=tag_type, html_attributes=dict(html_attributes))\n\n        node.is_inline = tag_type in self.INLINE_TAGS\n\n        self.tag_counts[tag_type] = self.tag_counts.get(tag_type, 0) + 1\n        node.set_retrieval_instructions(f\"SCRAPE 1 {tag_type} IN POSITION={self.tag_counts[tag_type]};\")\n\n        if self.root is None:\n            self.root = node\n            if tag_type not in self.VOID_TAGS:\n                self.stack.append(node)\n            return\n\n        parent = next((n for n in reversed(self.stack) if n is not None), self.root)\n        parent.children.append(node)\n        node.parent = parent\n\n        if tag_type not in self.VOID_TAGS:\n            self.stack.append(node)\n\n    def handle_endtag(self, tag_type: str) -&gt; None:\n        \"\"\"\n        \"\"\"\n        for i in range(len(self.stack)-1, -1, -1):\n            if self.stack[i].tag_type == tag_type:\n                del self.stack[i:]\n                break\n        return\n\n    def handle_data(self, data: str) -&gt; None:\n        \"\"\"\n        \"\"\"\n        stripped = data.strip()\n        if not stripped:\n            return\n\n        current = next((n for n in reversed(self.stack) if n is not None), self.root)\n\n        # Add text to current node\n        if current.body:\n            current.body += \" \" + stripped\n        else:\n            current.body = stripped\n        current.has_data = True\n\n        # Bubble text up if inline\n        if getattr(current, \"is_inline\", False) and current.parent is not None:\n            if current.parent.body:\n                current.parent.body += \" \" + stripped\n            else:\n                current.parent.body = stripped\n            current.parent.has_data = True\n\n    def _append_root_tag(self, raw_html: str) -&gt; str:\n        \"\"\"\n        \"\"\"\n        html_lower = raw_html.lower()\n\n        if \"&lt;html\" not in html_lower:\n            raw_html = f\"&lt;html&gt;{raw_html}&lt;/html&gt;\"\n\n        if \"&lt;body\" not in html_lower:\n            raw_html = raw_html.replace(\"&lt;html&gt;\", \"&lt;html&gt;&lt;body&gt;\", 1)\n            raw_html = raw_html.replace(\"&lt;/html&gt;\", \"&lt;/body&gt;&lt;/html&gt;\", 1)\n        return raw_html\n\n    def grow_tree(self, raw_html: str) -&gt; HTMLNode:\n        \"\"\"\n        Creates an HTMLNode tree from raw HTML input.\n\n        Args:\n            raw_html (str): The raw HTML string to be parsed.\n\n        Returns:\n            HTMLNode: The root node of the constructed HTMLNode tree.\n\n        Usage:\n            ```python\n            root_node = Gardener().grow_tree(\"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\")\n            ```\n\n        Warning:\n            Raises ScrapegoatParseException if the HTML cannot be parsed.\n        \"\"\"\n        self.root = None\n        self.stack = []\n        self.tag_counts = {}\n        self.reset()\n\n        wrapped_html = self._append_root_tag(raw_html)\n        try:\n            self.feed(wrapped_html)\n        except Exception as e:\n            raise ScrapegoatParseException(f\"Failed to parse HTML: {str(e)}\")\n        return self.root\n\n    def get_root(self) -&gt; HTMLNode:\n        \"\"\"\n        Returns the root HTMLNode of the parsed HTML tree.\n\n        Returns:\n            HTMLNode: The root node of the HTMLNode tree.\n\n        Usage:\n            ```python\n            gardener = Gardener()\n            # grow a tree first, else root will be None.\n            root_node = gardener.get_root()\n            ```\n        \"\"\"\n        return self.root\n</code></pre>"},{"location":"core/classes/gardener/#scrapegoat_core.classes.gardener.Gardener.__init__","title":"<code>__init__()</code>","text":"<p>Initializes an instance of the Gardener class.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/gardener.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes an instance of the Gardener class.\n    \"\"\"\n    super().__init__()\n    self.tag_counts = {}\n    self.root = None\n    self.stack = []\n</code></pre>"},{"location":"core/classes/gardener/#scrapegoat_core.classes.gardener.Gardener.get_root","title":"<code>get_root()</code>","text":"<p>Returns the root HTMLNode of the parsed HTML tree.</p> <p>Returns:</p> Name Type Description <code>HTMLNode</code> <code>HTMLNode</code> <p>The root node of the HTMLNode tree.</p> Usage <pre><code>gardener = Gardener()\n# grow a tree first, else root will be None.\nroot_node = gardener.get_root()\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/gardener.py</code> <pre><code>def get_root(self) -&gt; HTMLNode:\n    \"\"\"\n    Returns the root HTMLNode of the parsed HTML tree.\n\n    Returns:\n        HTMLNode: The root node of the HTMLNode tree.\n\n    Usage:\n        ```python\n        gardener = Gardener()\n        # grow a tree first, else root will be None.\n        root_node = gardener.get_root()\n        ```\n    \"\"\"\n    return self.root\n</code></pre>"},{"location":"core/classes/gardener/#scrapegoat_core.classes.gardener.Gardener.grow_tree","title":"<code>grow_tree(raw_html)</code>","text":"<p>Creates an HTMLNode tree from raw HTML input.</p> <p>Parameters:</p> Name Type Description Default <code>raw_html</code> <code>str</code> <p>The raw HTML string to be parsed.</p> required <p>Returns:</p> Name Type Description <code>HTMLNode</code> <code>HTMLNode</code> <p>The root node of the constructed HTMLNode tree.</p> Usage <pre><code>root_node = Gardener().grow_tree(\"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\")\n</code></pre> Warning <p>Raises ScrapegoatParseException if the HTML cannot be parsed.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/gardener.py</code> <pre><code>def grow_tree(self, raw_html: str) -&gt; HTMLNode:\n    \"\"\"\n    Creates an HTMLNode tree from raw HTML input.\n\n    Args:\n        raw_html (str): The raw HTML string to be parsed.\n\n    Returns:\n        HTMLNode: The root node of the constructed HTMLNode tree.\n\n    Usage:\n        ```python\n        root_node = Gardener().grow_tree(\"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\")\n        ```\n\n    Warning:\n        Raises ScrapegoatParseException if the HTML cannot be parsed.\n    \"\"\"\n    self.root = None\n    self.stack = []\n    self.tag_counts = {}\n    self.reset()\n\n    wrapped_html = self._append_root_tag(raw_html)\n    try:\n        self.feed(wrapped_html)\n    except Exception as e:\n        raise ScrapegoatParseException(f\"Failed to parse HTML: {str(e)}\")\n    return self.root\n</code></pre>"},{"location":"core/classes/goat/","title":"Goat Class","text":""},{"location":"core/classes/goat/#goat","title":"Goat","text":"<p>The Goat class is responsible for executing graze commands on an HTMLNode tree to select and scrape data.</p> Hint <p>This class is one of Scrapegoat's highly extendable classes. You can create your own Goat subclass to implement custom grazing behavior to use with the Shepherd master class.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/goat.py</code> <pre><code>class Goat:\n    \"\"\"\n    The Goat class is responsible for executing graze commands on an HTMLNode tree to select and scrape data.\n\n    Hint:\n        This class is one of Scrapegoat's highly extendable classes. You can create your own Goat subclass to implement custom grazing behavior to use with the Shepherd master class.\n    \"\"\"\n    def feast(self, root: \"HTMLNode\", graze_commands: [\"GrazeCommand\"]) -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Executes a series of graze commands starting from the given root node.\n\n        Args:\n            root (HTMLNode): The starting HTMLNode from which to execute the graze commands.\n            graze_commands ([\"GrazeCommand\"]): A list of GrazeCommand objects to be executed in sequence.\n\n        Returns:\n            A list of HTMLNode objects that are the result of executing the graze commands.\n\n        Usage:\n            ```python\n            root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\n            select_command = GrazeCommand(action=\"select\", parameters=...) \n            scrape_command = GrazeCommand(action=\"scrape\", parameters=...)\n\n            results = Goat().feast(root_node, [select_command, scrape_command])\n            ```\n        \"\"\"\n        results = []\n        i = 0\n        while i &lt; len(graze_commands):\n            graze_command = graze_commands[i]\n            if graze_command.action.lower() == \"select\":\n                rebased_roots = graze_command.execute(root)\n                graze_command_subset = graze_commands[i + 1:]\n                for new_root in rebased_roots:\n                    results.extend(self.feast(new_root, graze_command_subset))\n                return results\n            else:\n                results.extend(graze_command.execute(root))\n            i += 1\n        return results\n</code></pre>"},{"location":"core/classes/goat/#scrapegoat_core.classes.goat.Goat.feast","title":"<code>feast(root, graze_commands)</code>","text":"<p>Executes a series of graze commands starting from the given root node.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>HTMLNode</code> <p>The starting HTMLNode from which to execute the graze commands.</p> required <code>graze_commands</code> <code>[GrazeCommand]</code> <p>A list of GrazeCommand objects to be executed in sequence.</p> required <p>Returns:</p> Type Description <code>list[HTMLNode]</code> <p>A list of HTMLNode objects that are the result of executing the graze commands.</p> Usage <pre><code>root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\nselect_command = GrazeCommand(action=\"select\", parameters=...) \nscrape_command = GrazeCommand(action=\"scrape\", parameters=...)\n\nresults = Goat().feast(root_node, [select_command, scrape_command])\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/goat.py</code> <pre><code>def feast(self, root: \"HTMLNode\", graze_commands: [\"GrazeCommand\"]) -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Executes a series of graze commands starting from the given root node.\n\n    Args:\n        root (HTMLNode): The starting HTMLNode from which to execute the graze commands.\n        graze_commands ([\"GrazeCommand\"]): A list of GrazeCommand objects to be executed in sequence.\n\n    Returns:\n        A list of HTMLNode objects that are the result of executing the graze commands.\n\n    Usage:\n        ```python\n        root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\n        select_command = GrazeCommand(action=\"select\", parameters=...) \n        scrape_command = GrazeCommand(action=\"scrape\", parameters=...)\n\n        results = Goat().feast(root_node, [select_command, scrape_command])\n        ```\n    \"\"\"\n    results = []\n    i = 0\n    while i &lt; len(graze_commands):\n        graze_command = graze_commands[i]\n        if graze_command.action.lower() == \"select\":\n            rebased_roots = graze_command.execute(root)\n            graze_command_subset = graze_commands[i + 1:]\n            for new_root in rebased_roots:\n                results.extend(self.feast(new_root, graze_command_subset))\n            return results\n        else:\n            results.extend(graze_command.execute(root))\n        i += 1\n    return results\n</code></pre>"},{"location":"core/classes/interpreter/","title":"Interpreter Module","text":""},{"location":"core/classes/interpreter/#token-classes","title":"Token Classes","text":""},{"location":"core/classes/interpreter/#token","title":"Token","text":"<p>A data class representing a token in the goatspeak language.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class Token:\n    \"\"\"\n    A data class representing a token in the goatspeak language.\n    \"\"\"\n    def __init__(self, type: str, value: str):\n        \"\"\"\n        Initializes a Token instance.\n\n        Args:\n            type (str): The type of the token.\n            value (str): The value of the token.\n        \"\"\"\n        self.type = type\n        self.value = value\n\n    def __repr__(self):\n        \"\"\"\n        \"\"\"\n        return f\"Token(type={self.type}, value='{self.value}')\"\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.Token.__init__","title":"<code>__init__(type, value)</code>","text":"<p>Initializes a Token instance.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>The type of the token.</p> required <code>value</code> <code>str</code> <p>The value of the token.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self, type: str, value: str):\n    \"\"\"\n    Initializes a Token instance.\n\n    Args:\n        type (str): The type of the token.\n        value (str): The value of the token.\n    \"\"\"\n    self.type = type\n    self.value = value\n</code></pre>"},{"location":"core/classes/interpreter/#tokentype","title":"TokenType","text":"<p>               Bases: <code>Enum</code></p> <p>An Enum representing different types of tokens in the goatspeak language.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class TokenType(Enum):\n    \"\"\"\n    An Enum representing different types of tokens in the goatspeak language.\n    \"\"\"\n    ACTION = auto()\n    CONDITIONAL = auto()\n    KEYWORD = auto()\n    OPERATOR = auto()\n    NUMBER = auto()\n    IDENTIFIER = auto()\n    FILE_TYPE = auto()\n    NEGATION = auto()\n    FLAG = auto()\n    SEMICOLON = auto()\n    UNKNOWN = auto()\n</code></pre>"},{"location":"core/classes/interpreter/#tokenizer","title":"Tokenizer","text":"<p>A class responsible for tokenizing goatspeak queries.</p> <p>Attributes:</p> Name Type Description <code>ACTIONS</code> <code>set</code> <p>A set of valid action keywords.</p> <code>CONDITIONALS</code> <code>set</code> <p>A set of valid conditional keywords.</p> <code>KEYWORDS</code> <code>set</code> <p>A set of valid keywords.</p> <code>OPERATORS</code> <code>set</code> <p>A set of valid operators.</p> <code>NEGATIONS</code> <code>set</code> <p>A set of valid negation keywords.</p> <code>FILE_TYPES</code> <code>set</code> <p>A set of valid file type keywords.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class Tokenizer:\n    \"\"\"\n    A class responsible for tokenizing goatspeak queries.\n\n    Attributes:\n        ACTIONS (set): A set of valid action keywords.\n        CONDITIONALS (set): A set of valid conditional keywords.\n        KEYWORDS (set): A set of valid keywords.\n        OPERATORS (set): A set of valid operators.\n        NEGATIONS (set): A set of valid negation keywords.\n        FILE_TYPES (set): A set of valid file type keywords.\n    \"\"\"\n    ACTIONS = {\"select\", \"scrape\", \"extract\", \"output\", \"visit\"}\n    CONDITIONALS = {\"if\", \"in\"}\n    KEYWORDS = {\"position\"}\n    OPERATORS = {\"=\", \"!=\", \"like\"}\n    NEGATIONS = {\"not\"}\n    FILE_TYPES = {\"json\", \"csv\"}\n\n    def _preprocess_query(self, query: str) -&gt; str:\n        \"\"\"\n        \"\"\"\n        query = re.sub(r'\\[.*?\\]', '', query, flags=re.DOTALL)\n        query = re.sub(r'^\\s*!goatspeak\\s*', '', query, flags=re.IGNORECASE)\n        pattern = r\"\"\"\n            (?:'[^'\\\\]*(?:\\\\.[^'\\\\]*)*' |      # single-quoted string\n            \"[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\" |        # double-quoted string\n            //.*$                             # line comment\n            )\n        \"\"\"\n        def replacer(m):\n            s = m.group(0)\n            return '' if s.strip().startswith('//') else s\n\n        query = re.sub(pattern, replacer, query, flags=re.MULTILINE | re.VERBOSE)\n        return query\n\n    def tokenize(self, query: str) -&gt; list[Token]:\n        \"\"\"\n        Tokenizes a goatspeak query string into a list of Token objects.\n\n        Args:\n            query (str): The goatspeak query string to tokenize.\n\n        Returns:\n            list[Token]: A list of Token objects representing the tokenized query.\n        \"\"\"\n        query = self._preprocess_query(query)\n\n        tokens = []\n        pattern = (\n            r'(--[A-Za-z0-9_-]+|'\n            r'\\bSELECT\\b|\\bSCRAPE\\b|\\bEXTRACT\\b|\\bOUTPUT\\b|\\bVISIT\\b|\\bIN\\b|\\bIF\\b|\\bPOSITION\\b|\\bNOT\\b|\\bLIKE\\b|\\bJSON\\b|\\bCSV\\b|'\n            r'!=|==|=|;|\\n|'\n            r'\"(?:[^\"]*)\"|\\'(?:[^\\']*)\\'|'\n            r'@?[A-Za-z_][A-Za-z0-9_-]*|'\n            r'\\d+)'\n        )\n\n        for match in re.finditer(pattern, query.replace(\"\\n\", \"\"), flags=re.IGNORECASE):\n            raw_value = match.group(0)\n            token = self._classify_token(raw_value)\n            tokens.append(token)\n        return tokens\n\n    def _classify_token(self, raw_value: str) -&gt; Token:\n        \"\"\"\n        \"\"\"\n        if raw_value[0] in ('\"', \"'\") and raw_value[-1] == raw_value[0]:\n            return Token(TokenType.IDENTIFIER, raw_value[1:-1])\n        val_lower = raw_value.lower()\n        if val_lower.startswith(\"--\"):\n            return Token(TokenType.FLAG, val_lower[2:].replace(\"-\", \"_\"))\n        if val_lower in self.ACTIONS:\n            return Token(TokenType.ACTION, val_lower)\n        if val_lower in self.CONDITIONALS:\n            return Token(TokenType.CONDITIONAL, val_lower)\n        if val_lower in self.KEYWORDS:\n            return Token(TokenType.KEYWORD, val_lower)\n        if val_lower in self.OPERATORS:\n            return Token(TokenType.OPERATOR, val_lower)\n        if val_lower in self.NEGATIONS:\n            return Token(TokenType.NEGATION, val_lower)\n        if raw_value == \";\":\n            return Token(TokenType.SEMICOLON, raw_value)\n        if val_lower.isdigit():\n            return Token(TokenType.NUMBER, val_lower)\n        if val_lower in self.FILE_TYPES:\n            return Token(TokenType.FILE_TYPE, val_lower)\n        return Token(TokenType.IDENTIFIER, raw_value)\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.Tokenizer.tokenize","title":"<code>tokenize(query)</code>","text":"<p>Tokenizes a goatspeak query string into a list of Token objects.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The goatspeak query string to tokenize.</p> required <p>Returns:</p> Type Description <code>list[Token]</code> <p>list[Token]: A list of Token objects representing the tokenized query.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def tokenize(self, query: str) -&gt; list[Token]:\n    \"\"\"\n    Tokenizes a goatspeak query string into a list of Token objects.\n\n    Args:\n        query (str): The goatspeak query string to tokenize.\n\n    Returns:\n        list[Token]: A list of Token objects representing the tokenized query.\n    \"\"\"\n    query = self._preprocess_query(query)\n\n    tokens = []\n    pattern = (\n        r'(--[A-Za-z0-9_-]+|'\n        r'\\bSELECT\\b|\\bSCRAPE\\b|\\bEXTRACT\\b|\\bOUTPUT\\b|\\bVISIT\\b|\\bIN\\b|\\bIF\\b|\\bPOSITION\\b|\\bNOT\\b|\\bLIKE\\b|\\bJSON\\b|\\bCSV\\b|'\n        r'!=|==|=|;|\\n|'\n        r'\"(?:[^\"]*)\"|\\'(?:[^\\']*)\\'|'\n        r'@?[A-Za-z_][A-Za-z0-9_-]*|'\n        r'\\d+)'\n    )\n\n    for match in re.finditer(pattern, query.replace(\"\\n\", \"\"), flags=re.IGNORECASE):\n        raw_value = match.group(0)\n        token = self._classify_token(raw_value)\n        tokens.append(token)\n    return tokens\n</code></pre>"},{"location":"core/classes/interpreter/#interpreter","title":"Interpreter","text":"<p>A class responsible for interpreting goatspeak queries into executable commands.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class Interpreter:\n    \"\"\"\n    A class responsible for interpreting goatspeak queries into executable commands.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initializes an Interpreter instance.\n\n        Attributes:\n            tokenizer (Tokenizer): An instance of Tokenizer to tokenize queries.\n            condition_parser (ConditionParser): An instance of ConditionParser to parse conditions.\n            flag_parser (FlagParser): An instance of FlagParser to parse flags.\n            action_parsers (dict): A dictionary mapping action keywords to their respective parser instances.\n        \"\"\"\n        self.tokenizer = Tokenizer()\n        self.condition_parser = ConditionParser()\n        self.flag_parser = FlagParser()\n        self.action_parsers = {\n            \"visit\": VisitParser(self.flag_parser),\n            \"scrape\": ScrapeSelectParser(self.condition_parser, self.flag_parser),\n            \"select\": ScrapeSelectParser(self.condition_parser, self.flag_parser),\n            \"extract\": ExtractParser(self.flag_parser),\n            \"output\": OutputParser(self.flag_parser),\n        }\n\n    def _manage_interpreter_state(self, instructions, goatspeak_blocks) -&gt; tuple:\n        \"\"\"\n        \"\"\"\n        if len(instructions) &gt;= 2 and instructions[-2].action in (\"scrape\", \"extract\", \"output\") and instructions[-1].action in (\"scrape\", \"select\", \"visit\"):\n            current_instructions = instructions[:-1]\n            next_instruction = instructions[-1]\n\n            fetch_command = next((cmd for cmd in current_instructions if cmd.action == \"visit\"), None)\n            graze_commands = [cmd for cmd in current_instructions if cmd.action in (\"scrape\", \"select\")]\n            churn_command = next((cmd for cmd in current_instructions if cmd.action == \"extract\"), None)\n            deliver_command = next((cmd for cmd in current_instructions if cmd.action == \"output\"), None)\n\n            query = Query(\n                graze_commands=graze_commands,\n                fetch_command=fetch_command,\n                churn_command=churn_command,\n                deliver_command=deliver_command,\n            )\n\n            instructions = [next_instruction]\n            last_block = goatspeak_blocks[-1]\n            last_block.query_list.append(query)\n\n        if instructions[-1].action == \"visit\":\n            fetch_command = instructions[-1]\n            goatspeak_blocks.append(GoatspeakBlock(fetch_command=fetch_command, query_list=[]))\n            instructions = [fetch_command]\n            return instructions, goatspeak_blocks\n\n        return instructions, goatspeak_blocks\n\n    def interpret(self, query: str) -&gt; list[GoatspeakBlock]:\n        \"\"\"\n        Interprets a goatspeak query string into a list of GoatspeakBlock objects.\n\n        Args:\n            query (str): The goatspeak query string to interpret.\n\n        Returns:\n            list[GoatspeakBlock]: A list of GoatspeakBlock objects representing the interpreted\n\n        Warning:\n            Raises GoatspeakInterpreterException if the goatspeak syntax is invalid.\n        \"\"\"\n        tokens = self.tokenizer.tokenize(query)\n        instructions = []\n        goatspeak_blocks = []\n        index = 0\n\n        while index &lt; len(tokens):\n            token = tokens[index]\n            if token.type != TokenType.ACTION:\n                raise GoatspeakInterpreterException(f\"Expected action at token {token}\")\n\n            parser = self.action_parsers.get(token.value)\n\n            if parser is None:\n                raise GoatspeakInterpreterException(f\"Unknown action '{token.value}' at token {token}\")\n\n            try:\n                instruction, index = parser.parse(tokens, index)\n            except IndexError:\n                raise GoatspeakInterpreterException(f\"Missing semicolon at end of command starting with token {token}\")\n            except Exception as e:\n                raise GoatspeakInterpreterException(f\"Error parsing command starting with token {token}: {str(e)}\")\n\n            instructions.append(instruction)\n            instructions, goatspeak_blocks = self._manage_interpreter_state(instructions, goatspeak_blocks)\n\n        if instructions:\n            fetch_command = next((cmd for cmd in instructions if cmd.action == \"visit\"), None)\n            graze_commands = [cmd for cmd in instructions if cmd.action in (\"scrape\", \"select\")]\n            churn_command = next((cmd for cmd in instructions if cmd.action == \"extract\"), None)\n            deliver_command = next((cmd for cmd in instructions if cmd.action == \"output\"), None)\n\n            query = Query(\n                graze_commands=graze_commands,\n                fetch_command=fetch_command,\n                churn_command=churn_command,\n                deliver_command=deliver_command,\n            )\n\n            if not goatspeak_blocks:\n                goatspeak_blocks.append(GoatspeakBlock(fetch_command=fetch_command, query_list=[query]))\n            else:\n                last_block = goatspeak_blocks[-1]\n                last_block.query_list.append(query)\n        return goatspeak_blocks\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.Interpreter.__init__","title":"<code>__init__()</code>","text":"<p>Initializes an Interpreter instance.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <code>Tokenizer</code> <p>An instance of Tokenizer to tokenize queries.</p> <code>condition_parser</code> <code>ConditionParser</code> <p>An instance of ConditionParser to parse conditions.</p> <code>flag_parser</code> <code>FlagParser</code> <p>An instance of FlagParser to parse flags.</p> <code>action_parsers</code> <code>dict</code> <p>A dictionary mapping action keywords to their respective parser instances.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes an Interpreter instance.\n\n    Attributes:\n        tokenizer (Tokenizer): An instance of Tokenizer to tokenize queries.\n        condition_parser (ConditionParser): An instance of ConditionParser to parse conditions.\n        flag_parser (FlagParser): An instance of FlagParser to parse flags.\n        action_parsers (dict): A dictionary mapping action keywords to their respective parser instances.\n    \"\"\"\n    self.tokenizer = Tokenizer()\n    self.condition_parser = ConditionParser()\n    self.flag_parser = FlagParser()\n    self.action_parsers = {\n        \"visit\": VisitParser(self.flag_parser),\n        \"scrape\": ScrapeSelectParser(self.condition_parser, self.flag_parser),\n        \"select\": ScrapeSelectParser(self.condition_parser, self.flag_parser),\n        \"extract\": ExtractParser(self.flag_parser),\n        \"output\": OutputParser(self.flag_parser),\n    }\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.Interpreter.interpret","title":"<code>interpret(query)</code>","text":"<p>Interprets a goatspeak query string into a list of GoatspeakBlock objects.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The goatspeak query string to interpret.</p> required <p>Returns:</p> Type Description <code>list[GoatspeakBlock]</code> <p>list[GoatspeakBlock]: A list of GoatspeakBlock objects representing the interpreted</p> Warning <p>Raises GoatspeakInterpreterException if the goatspeak syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def interpret(self, query: str) -&gt; list[GoatspeakBlock]:\n    \"\"\"\n    Interprets a goatspeak query string into a list of GoatspeakBlock objects.\n\n    Args:\n        query (str): The goatspeak query string to interpret.\n\n    Returns:\n        list[GoatspeakBlock]: A list of GoatspeakBlock objects representing the interpreted\n\n    Warning:\n        Raises GoatspeakInterpreterException if the goatspeak syntax is invalid.\n    \"\"\"\n    tokens = self.tokenizer.tokenize(query)\n    instructions = []\n    goatspeak_blocks = []\n    index = 0\n\n    while index &lt; len(tokens):\n        token = tokens[index]\n        if token.type != TokenType.ACTION:\n            raise GoatspeakInterpreterException(f\"Expected action at token {token}\")\n\n        parser = self.action_parsers.get(token.value)\n\n        if parser is None:\n            raise GoatspeakInterpreterException(f\"Unknown action '{token.value}' at token {token}\")\n\n        try:\n            instruction, index = parser.parse(tokens, index)\n        except IndexError:\n            raise GoatspeakInterpreterException(f\"Missing semicolon at end of command starting with token {token}\")\n        except Exception as e:\n            raise GoatspeakInterpreterException(f\"Error parsing command starting with token {token}: {str(e)}\")\n\n        instructions.append(instruction)\n        instructions, goatspeak_blocks = self._manage_interpreter_state(instructions, goatspeak_blocks)\n\n    if instructions:\n        fetch_command = next((cmd for cmd in instructions if cmd.action == \"visit\"), None)\n        graze_commands = [cmd for cmd in instructions if cmd.action in (\"scrape\", \"select\")]\n        churn_command = next((cmd for cmd in instructions if cmd.action == \"extract\"), None)\n        deliver_command = next((cmd for cmd in instructions if cmd.action == \"output\"), None)\n\n        query = Query(\n            graze_commands=graze_commands,\n            fetch_command=fetch_command,\n            churn_command=churn_command,\n            deliver_command=deliver_command,\n        )\n\n        if not goatspeak_blocks:\n            goatspeak_blocks.append(GoatspeakBlock(fetch_command=fetch_command, query_list=[query]))\n        else:\n            last_block = goatspeak_blocks[-1]\n            last_block.query_list.append(query)\n    return goatspeak_blocks\n</code></pre>"},{"location":"core/classes/interpreter/#abstract-parser","title":"Abstract Parser","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all parsers to inherit from.</p> Important <p>This is an abstract base class and cannot be instantiated directly. Subclasses must implement the <code>parse</code> method to define specific parsing logic.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class Parser(ABC):\n    \"\"\"\n    Abstract base class for all parsers to inherit from.\n\n    Important:\n        This is an abstract base class and cannot be instantiated directly.\n        Subclasses must implement the `parse` method to define specific parsing logic.\n    \"\"\"\n    @abstractmethod\n    def parse(self, tokens: list[Token], index) -&gt; tuple[object, int]:\n        \"\"\"\n        Parses tokens starting from the given index and returns a command object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing the parsed command object and the updated index.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.Parser.parse","title":"<code>parse(tokens, index)</code>  <code>abstractmethod</code>","text":"<p>Parses tokens starting from the given index and returns a command object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[object, int]</code> <p>A tuple containing the parsed command object and the updated index.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>@abstractmethod\ndef parse(self, tokens: list[Token], index) -&gt; tuple[object, int]:\n    \"\"\"\n    Parses tokens starting from the given index and returns a command object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing the parsed command object and the updated index.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/classes/interpreter/#parsers","title":"Parsers","text":""},{"location":"core/classes/interpreter/#flagparser","title":"FlagParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for flags in goatspeak commands.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class FlagParser(Parser):\n    \"\"\"\n    A parser for flags in goatspeak commands.\n    \"\"\"\n    def parse(self, tokens: list[Token], index: int) -&gt; tuple[dict, int]:\n        \"\"\"\n        Parses flags starting from the given index and returns a dictionary of flags and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing a dictionary of flags and the updated index.\n\n        Warning:\n            Raises GoatspeakInterpreterException if the flag syntax is invalid.\n        \"\"\"\n        flags = {}\n\n        while tokens[index].type != TokenType.SEMICOLON:\n            token = tokens[index]\n            if token.type != TokenType.FLAG:\n                raise GoatspeakInterpreterException(f\"Expected flag at token {token}\")\n            flag_name = token.value\n            index += 1\n            token = tokens[index]\n            if token.type != TokenType.IDENTIFIER:\n                flag_value = True\n            else:\n                flag_value = token.value\n                index += 1\n            flags[flag_name] = flag_value\n        return flags, index\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.FlagParser.parse","title":"<code>parse(tokens, index)</code>","text":"<p>Parses flags starting from the given index and returns a dictionary of flags and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[dict, int]</code> <p>A tuple containing a dictionary of flags and the updated index.</p> Warning <p>Raises GoatspeakInterpreterException if the flag syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int) -&gt; tuple[dict, int]:\n    \"\"\"\n    Parses flags starting from the given index and returns a dictionary of flags and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing a dictionary of flags and the updated index.\n\n    Warning:\n        Raises GoatspeakInterpreterException if the flag syntax is invalid.\n    \"\"\"\n    flags = {}\n\n    while tokens[index].type != TokenType.SEMICOLON:\n        token = tokens[index]\n        if token.type != TokenType.FLAG:\n            raise GoatspeakInterpreterException(f\"Expected flag at token {token}\")\n        flag_name = token.value\n        index += 1\n        token = tokens[index]\n        if token.type != TokenType.IDENTIFIER:\n            flag_value = True\n        else:\n            flag_value = token.value\n            index += 1\n        flags[flag_name] = flag_value\n    return flags, index\n</code></pre>"},{"location":"core/classes/interpreter/#conditionparser","title":"ConditionParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for conditions in goatspeak commands.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class ConditionParser(Parser):\n    \"\"\"\n    A parser for conditions in goatspeak commands.\n    \"\"\"\n    def parse(self, tokens: list[Token], index: int, element: str) -&gt; tuple[\"Condition\", int]: # type: ignore\n        \"\"\"\n        Parses a condition starting from the given index and returns a condition object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n            element (str): The element type being queried.\n\n        Returns:\n            tuple: A tuple containing the parsed condition object and the updated index.\n\n        Warning:\n            Raises GoatspeakInterpreterException if the condition syntax is invalid.\n        \"\"\"\n        negated = False\n        if tokens[index].type == TokenType.NEGATION:\n            negated = True\n            index += 1\n        token = tokens[index]\n        if token.type != TokenType.CONDITIONAL:\n            raise GoatspeakInterpreterException(f\"Expected conditional at {token}\")\n        if token.value == \"if\":\n            return self._parse_if(tokens, index, element, negated)\n        elif token.value == \"in\":\n            return self._parse_in(tokens, index, element, negated)\n\n    def _parse_if(self, tokens, index, element, negated) -&gt; tuple:\n        \"\"\"\n        \"\"\"\n        index += 1\n        token = tokens[index]\n        if token.type != TokenType.IDENTIFIER:\n            raise GoatspeakInterpreterException(f\"Expected key after IF at {token}\")\n        key = token.value\n        index += 1\n        token = tokens[index]\n        if token.type != TokenType.OPERATOR:\n            condition = IfCondition(key=key, value=None, negated=negated, query_tag=element)\n            return condition, index\n        if token.value == \"!=\":\n            negated = True\n        like = token.value == \"like\"\n        index += 1\n        token = tokens[index]\n        if token.type not in {TokenType.IDENTIFIER, TokenType.NUMBER}:\n            raise GoatspeakInterpreterException(f\"Expected value after IF {key} = at {token}\")\n        value = token.value\n        condition = IfCondition(key=key, value=value, negated=negated, query_tag=element, like=like)\n        index += 1\n        return condition, index\n\n    def _parse_in(self, tokens, index, element, negated) -&gt; tuple:\n        \"\"\"\n        \"\"\"\n        index += 1\n        token = tokens[index]\n        if token.type == TokenType.KEYWORD:\n            index += 1\n            token = tokens[index]\n            if token.type != TokenType.OPERATOR:\n                raise GoatspeakInterpreterException(f\"Expected '=' after IN POSITION at {token}\")\n            if token.value == \"!=\":\n                negated = True\n            index += 1\n            token = tokens[index]\n            if token.type != TokenType.NUMBER:\n                raise GoatspeakInterpreterException(f\"Expected number after IN POSITION = at {token}\")\n            position = int(token.value)\n            condition = InCondition(target=\"POSITION\", value=position, negated=negated, query_tag=element)\n        else:\n            if token.type != TokenType.IDENTIFIER:\n                raise GoatspeakInterpreterException(f\"Expected element after IN at {token}\")\n            target = token.value\n            condition = InCondition(target=target, negated=negated, query_tag=element)\n        index += 1\n        return condition, index\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.ConditionParser.parse","title":"<code>parse(tokens, index, element)</code>","text":"<p>Parses a condition starting from the given index and returns a condition object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <code>element</code> <code>str</code> <p>The element type being queried.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Condition, int]</code> <p>A tuple containing the parsed condition object and the updated index.</p> Warning <p>Raises GoatspeakInterpreterException if the condition syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int, element: str) -&gt; tuple[\"Condition\", int]: # type: ignore\n    \"\"\"\n    Parses a condition starting from the given index and returns a condition object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n        element (str): The element type being queried.\n\n    Returns:\n        tuple: A tuple containing the parsed condition object and the updated index.\n\n    Warning:\n        Raises GoatspeakInterpreterException if the condition syntax is invalid.\n    \"\"\"\n    negated = False\n    if tokens[index].type == TokenType.NEGATION:\n        negated = True\n        index += 1\n    token = tokens[index]\n    if token.type != TokenType.CONDITIONAL:\n        raise GoatspeakInterpreterException(f\"Expected conditional at {token}\")\n    if token.value == \"if\":\n        return self._parse_if(tokens, index, element, negated)\n    elif token.value == \"in\":\n        return self._parse_in(tokens, index, element, negated)\n</code></pre>"},{"location":"core/classes/interpreter/#scrapeselectparser","title":"ScrapeSelectParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for scrape/select commands in goatspeak.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class ScrapeSelectParser(Parser):\n    \"\"\"\n    A parser for scrape/select commands in goatspeak.\n    \"\"\"\n    def __init__(self, condition_parser: ConditionParser, flag_parser: FlagParser):\n        \"\"\"\n        Initializes a ScrapeSelectParser instance.\n\n        Args:\n            condition_parser (ConditionParser): An instance of ConditionParser to parse conditions.\n            flag_parser (FlagParser): An instance of FlagParser to parse flags.\n        \"\"\"\n        self.condition_parser = condition_parser\n        self.flag_parser = flag_parser\n\n    def parse(self, tokens: list[Token], index: int) -&gt; tuple[GrazeCommand, int]:\n        \"\"\"\n        Parses a scrape/select command starting from the given index and returns a GrazeCommand object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing the parsed GrazeCommand object and the updated index.\n\n        Warning:\n            Raises GoatspeakInterpreterException if the scrape syntax is invalid.\n        \"\"\"\n        action = tokens[index].value\n        index += 1\n\n        # count\n        count = 0\n        if tokens[index].type == TokenType.NUMBER:\n            count = int(tokens[index].value)\n            index += 1\n\n        # element\n        if tokens[index].type != TokenType.IDENTIFIER:\n            raise GoatspeakInterpreterException(f\"Expected element at token {tokens[index]}\")\n        element = tokens[index].value\n        index += 1\n\n        # conditions\n        conditions = []\n        while tokens[index].type != TokenType.SEMICOLON and tokens[index].type != TokenType.FLAG:\n            condition, index = self.condition_parser.parse(tokens, index, element)\n            conditions.append(condition)\n\n        # flags\n        flags = {}\n        if tokens[index].type == TokenType.FLAG:\n            flags, index = self.flag_parser.parse(tokens, index)\n\n        instruction = GrazeCommand(action=action, count=count, element=element, conditions=conditions, **flags)\n        return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.ScrapeSelectParser.__init__","title":"<code>__init__(condition_parser, flag_parser)</code>","text":"<p>Initializes a ScrapeSelectParser instance.</p> <p>Parameters:</p> Name Type Description Default <code>condition_parser</code> <code>ConditionParser</code> <p>An instance of ConditionParser to parse conditions.</p> required <code>flag_parser</code> <code>FlagParser</code> <p>An instance of FlagParser to parse flags.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self, condition_parser: ConditionParser, flag_parser: FlagParser):\n    \"\"\"\n    Initializes a ScrapeSelectParser instance.\n\n    Args:\n        condition_parser (ConditionParser): An instance of ConditionParser to parse conditions.\n        flag_parser (FlagParser): An instance of FlagParser to parse flags.\n    \"\"\"\n    self.condition_parser = condition_parser\n    self.flag_parser = flag_parser\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.ScrapeSelectParser.parse","title":"<code>parse(tokens, index)</code>","text":"<p>Parses a scrape/select command starting from the given index and returns a GrazeCommand object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[GrazeCommand, int]</code> <p>A tuple containing the parsed GrazeCommand object and the updated index.</p> Warning <p>Raises GoatspeakInterpreterException if the scrape syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int) -&gt; tuple[GrazeCommand, int]:\n    \"\"\"\n    Parses a scrape/select command starting from the given index and returns a GrazeCommand object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing the parsed GrazeCommand object and the updated index.\n\n    Warning:\n        Raises GoatspeakInterpreterException if the scrape syntax is invalid.\n    \"\"\"\n    action = tokens[index].value\n    index += 1\n\n    # count\n    count = 0\n    if tokens[index].type == TokenType.NUMBER:\n        count = int(tokens[index].value)\n        index += 1\n\n    # element\n    if tokens[index].type != TokenType.IDENTIFIER:\n        raise GoatspeakInterpreterException(f\"Expected element at token {tokens[index]}\")\n    element = tokens[index].value\n    index += 1\n\n    # conditions\n    conditions = []\n    while tokens[index].type != TokenType.SEMICOLON and tokens[index].type != TokenType.FLAG:\n        condition, index = self.condition_parser.parse(tokens, index, element)\n        conditions.append(condition)\n\n    # flags\n    flags = {}\n    if tokens[index].type == TokenType.FLAG:\n        flags, index = self.flag_parser.parse(tokens, index)\n\n    instruction = GrazeCommand(action=action, count=count, element=element, conditions=conditions, **flags)\n    return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#extractparser","title":"ExtractParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for extract commands in goatspeak.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class ExtractParser(Parser):\n    \"\"\"\n    A parser for extract commands in goatspeak.\n    \"\"\"\n    def __init__(self, flag_parser: FlagParser):\n        \"\"\"\n        Initializes an ExtractParser instance.\n\n        Args:\n            flag_parser (FlagParser): An instance of FlagParser to parse flags.\n        \"\"\"\n        self.flag_parser = flag_parser\n\n    def parse(self, tokens: list[Token], index: int) -&gt; tuple[ChurnCommand, int]:\n        \"\"\"\n        Parses an extract command starting from the given index and returns a ChurnCommand object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing the parsed ChurnCommand object and the updated index.\n        \"\"\"\n        fields = []\n\n        index += 1\n\n        # fields\n        while tokens[index].type != TokenType.SEMICOLON and tokens[index].type != TokenType.FLAG:\n            if tokens[index].type == TokenType.IDENTIFIER:\n                fields.append(tokens[index].value)\n            index += 1\n\n        # flags\n        flags = {}\n        if tokens[index].type == TokenType.FLAG:\n            flags, index = self.flag_parser.parse(tokens, index)\n\n        instruction = ChurnCommand(fields=fields, **flags)\n        return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.ExtractParser.__init__","title":"<code>__init__(flag_parser)</code>","text":"<p>Initializes an ExtractParser instance.</p> <p>Parameters:</p> Name Type Description Default <code>flag_parser</code> <code>FlagParser</code> <p>An instance of FlagParser to parse flags.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self, flag_parser: FlagParser):\n    \"\"\"\n    Initializes an ExtractParser instance.\n\n    Args:\n        flag_parser (FlagParser): An instance of FlagParser to parse flags.\n    \"\"\"\n    self.flag_parser = flag_parser\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.ExtractParser.parse","title":"<code>parse(tokens, index)</code>","text":"<p>Parses an extract command starting from the given index and returns a ChurnCommand object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[ChurnCommand, int]</code> <p>A tuple containing the parsed ChurnCommand object and the updated index.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int) -&gt; tuple[ChurnCommand, int]:\n    \"\"\"\n    Parses an extract command starting from the given index and returns a ChurnCommand object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing the parsed ChurnCommand object and the updated index.\n    \"\"\"\n    fields = []\n\n    index += 1\n\n    # fields\n    while tokens[index].type != TokenType.SEMICOLON and tokens[index].type != TokenType.FLAG:\n        if tokens[index].type == TokenType.IDENTIFIER:\n            fields.append(tokens[index].value)\n        index += 1\n\n    # flags\n    flags = {}\n    if tokens[index].type == TokenType.FLAG:\n        flags, index = self.flag_parser.parse(tokens, index)\n\n    instruction = ChurnCommand(fields=fields, **flags)\n    return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#outputparser","title":"OutputParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for output commands in goatspeak.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class OutputParser(Parser):\n    \"\"\"\n    A parser for output commands in goatspeak.\n    \"\"\"\n    def __init__(self, flag_parser: FlagParser):\n        \"\"\"\n        Initializes an OutputParser instance.\n\n        Args:\n            flag_parser (FlagParser): An instance of FlagParser to parse flags.\n        \"\"\"\n        self.flag_parser = flag_parser\n\n    def parse(self, tokens: list[Token], index: int) -&gt; tuple[DeliverCommand, int]:\n        \"\"\"\n        Parses an output command starting from the given index and returns a DeliverCommand object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing the parsed DeliverCommand object and the updated index.\n\n        Warning:\n            Raises GoatspeakInterpreterException if the output syntax is invalid.\n        \"\"\"\n        index += 1\n\n        # file type\n        if tokens[index].type != TokenType.FILE_TYPE:\n            raise GoatspeakInterpreterException(f\"Expected file type at token {tokens[index]}\")\n        file_type = tokens[index].value\n        index += 1\n\n        # flags\n        flags = {}\n        if tokens[index].type == TokenType.FLAG:\n            flags, index = self.flag_parser.parse(tokens, index)\n\n        instruction = DeliverCommand(file_type=file_type, **flags)\n        return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.OutputParser.__init__","title":"<code>__init__(flag_parser)</code>","text":"<p>Initializes an OutputParser instance.</p> <p>Parameters:</p> Name Type Description Default <code>flag_parser</code> <code>FlagParser</code> <p>An instance of FlagParser to parse flags.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self, flag_parser: FlagParser):\n    \"\"\"\n    Initializes an OutputParser instance.\n\n    Args:\n        flag_parser (FlagParser): An instance of FlagParser to parse flags.\n    \"\"\"\n    self.flag_parser = flag_parser\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.OutputParser.parse","title":"<code>parse(tokens, index)</code>","text":"<p>Parses an output command starting from the given index and returns a DeliverCommand object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[DeliverCommand, int]</code> <p>A tuple containing the parsed DeliverCommand object and the updated index.</p> Warning <p>Raises GoatspeakInterpreterException if the output syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int) -&gt; tuple[DeliverCommand, int]:\n    \"\"\"\n    Parses an output command starting from the given index and returns a DeliverCommand object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing the parsed DeliverCommand object and the updated index.\n\n    Warning:\n        Raises GoatspeakInterpreterException if the output syntax is invalid.\n    \"\"\"\n    index += 1\n\n    # file type\n    if tokens[index].type != TokenType.FILE_TYPE:\n        raise GoatspeakInterpreterException(f\"Expected file type at token {tokens[index]}\")\n    file_type = tokens[index].value\n    index += 1\n\n    # flags\n    flags = {}\n    if tokens[index].type == TokenType.FLAG:\n        flags, index = self.flag_parser.parse(tokens, index)\n\n    instruction = DeliverCommand(file_type=file_type, **flags)\n    return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#visitparser","title":"VisitParser","text":"<p>               Bases: <code>Parser</code></p> <p>A parser for visit commands in goatspeak.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>class VisitParser(Parser):\n    \"\"\"\n    A parser for visit commands in goatspeak.\n    \"\"\"\n    def __init__(self, flag_parser: FlagParser):\n        \"\"\"\n        Initializes a VisitParser instance.\n\n        Args:\n            flag_parser (FlagParser): An instance of FlagParser to parse flags.\n        \"\"\"\n        self.flag_parser = flag_parser\n\n    def parse(self, tokens: list[Token], index: int) -&gt; tuple[FetchCommand, int]:\n        \"\"\"\n        Parses a visit command starting from the given index and returns a FetchCommand object and the new index.\n\n        Args:\n            tokens (list[Token]): The list of tokens to parse.\n            index (int): The current index in the token list.\n\n        Returns:\n            tuple: A tuple containing the parsed FetchCommand object and the updated index.\n\n        Warning:\n            Raises GoatspeakInterpreterException if the visit syntax is invalid.\n        \"\"\"\n        index += 1\n\n        # url\n        if tokens[index].type != TokenType.IDENTIFIER:\n            raise GoatspeakInterpreterException(f\"Expected URL at token {tokens[index]}\")\n        url = tokens[index].value\n        index += 1\n\n        # flags\n        flags = {}\n        if tokens[index].type == TokenType.FLAG:\n            flags, index = self.flag_parser.parse(tokens, index)\n\n        instruction = FetchCommand(url=url, **flags)\n        return instruction, index + 1\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.VisitParser.__init__","title":"<code>__init__(flag_parser)</code>","text":"<p>Initializes a VisitParser instance.</p> <p>Parameters:</p> Name Type Description Default <code>flag_parser</code> <code>FlagParser</code> <p>An instance of FlagParser to parse flags.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def __init__(self, flag_parser: FlagParser):\n    \"\"\"\n    Initializes a VisitParser instance.\n\n    Args:\n        flag_parser (FlagParser): An instance of FlagParser to parse flags.\n    \"\"\"\n    self.flag_parser = flag_parser\n</code></pre>"},{"location":"core/classes/interpreter/#scrapegoat_core.classes.interpreter.VisitParser.parse","title":"<code>parse(tokens, index)</code>","text":"<p>Parses a visit command starting from the given index and returns a FetchCommand object and the new index.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[Token]</code> <p>The list of tokens to parse.</p> required <code>index</code> <code>int</code> <p>The current index in the token list.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[FetchCommand, int]</code> <p>A tuple containing the parsed FetchCommand object and the updated index.</p> Warning <p>Raises GoatspeakInterpreterException if the visit syntax is invalid.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/interpreter.py</code> <pre><code>def parse(self, tokens: list[Token], index: int) -&gt; tuple[FetchCommand, int]:\n    \"\"\"\n    Parses a visit command starting from the given index and returns a FetchCommand object and the new index.\n\n    Args:\n        tokens (list[Token]): The list of tokens to parse.\n        index (int): The current index in the token list.\n\n    Returns:\n        tuple: A tuple containing the parsed FetchCommand object and the updated index.\n\n    Warning:\n        Raises GoatspeakInterpreterException if the visit syntax is invalid.\n    \"\"\"\n    index += 1\n\n    # url\n    if tokens[index].type != TokenType.IDENTIFIER:\n        raise GoatspeakInterpreterException(f\"Expected URL at token {tokens[index]}\")\n    url = tokens[index].value\n    index += 1\n\n    # flags\n    flags = {}\n    if tokens[index].type == TokenType.FLAG:\n        flags, index = self.flag_parser.parse(tokens, index)\n\n    instruction = FetchCommand(url=url, **flags)\n    return instruction, index + 1\n</code></pre>"},{"location":"core/classes/milkmaid/","title":"Milkmaid Class","text":""},{"location":"core/classes/milkmaid/#milkmaid","title":"Milkmaid","text":"<p>Milkmaid class responsible for extracting the desired data from scraped HTMLNode results based on churn commands.</p> Hint <p>This class is one of Scrapegoat's highly extendable classes. You can create your own Milkmaid subclass to implement custom data extraction behavior to use with the Shepherd master class.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/milkmaid.py</code> <pre><code>class Milkmaid:\n    \"\"\"\n    Milkmaid class responsible for extracting the desired data from scraped HTMLNode results based on churn commands.\n\n    Hint:\n        This class is one of Scrapegoat's highly extendable classes. You can create your own Milkmaid subclass to implement custom data extraction behavior to use with the Shepherd master class.\n    \"\"\"\n    def churn(self, results: list[\"HTMLNode\"], churn_command: \"ChurnCommand\") -&gt; None: # type: ignore\n        \"\"\"\n        Updates the HTMLNodes representation to extract data according to the specified ChurnCommand.\n\n        Args:\n            results (list): A list of scraped HTMLNode results.\n            churn_command (ChurnCommand): The ChurnCommand object that specifies how to extract data from each result.\n\n        Usage:\n            ```python\n            Milkmaid().churn(results, churn_command)\n            ```\n        \"\"\"\n        for node in results:\n            churn_command.execute(node)\n        return\n</code></pre>"},{"location":"core/classes/milkmaid/#scrapegoat_core.classes.milkmaid.Milkmaid.churn","title":"<code>churn(results, churn_command)</code>","text":"<p>Updates the HTMLNodes representation to extract data according to the specified ChurnCommand.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list</code> <p>A list of scraped HTMLNode results.</p> required <code>churn_command</code> <code>ChurnCommand</code> <p>The ChurnCommand object that specifies how to extract data from each result.</p> required Usage <pre><code>Milkmaid().churn(results, churn_command)\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/milkmaid.py</code> <pre><code>def churn(self, results: list[\"HTMLNode\"], churn_command: \"ChurnCommand\") -&gt; None: # type: ignore\n    \"\"\"\n    Updates the HTMLNodes representation to extract data according to the specified ChurnCommand.\n\n    Args:\n        results (list): A list of scraped HTMLNode results.\n        churn_command (ChurnCommand): The ChurnCommand object that specifies how to extract data from each result.\n\n    Usage:\n        ```python\n        Milkmaid().churn(results, churn_command)\n        ```\n    \"\"\"\n    for node in results:\n        churn_command.execute(node)\n    return\n</code></pre>"},{"location":"core/classes/milkman/","title":"Milkman Class","text":""},{"location":"core/classes/milkman/#milkman","title":"Milkman","text":"<p>The Milkman class is responsible for handling the file operations related to goatspeak scripts. It provides methods to read goatspeak scripts from files and deliver scraped results to specified destinations.</p> Hint <p>This class is one of Scrapegoat's highly extendable classes. You can create your own Milkman subclass to implement custom file handling behavior to use with the Shepherd master class.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/milkman.py</code> <pre><code>class Milkman:\n    \"\"\"\n    The Milkman class is responsible for handling the file operations related to goatspeak scripts. It provides methods to read goatspeak scripts from files and deliver scraped results to specified destinations.\n\n    Hint:\n        This class is one of Scrapegoat's highly extendable classes. You can create your own Milkman subclass to implement custom file handling behavior to use with the Shepherd master class.\n    \"\"\"\n    def deliver(self, results: list[\"HTMLNode\"], deliver_command: \"DeliverCommand\") -&gt; None: # type: ignore\n        \"\"\"\n        Delivers the scraped results using the specified DeliverCommand.\n\n        Args:\n            results (list): A list of scraped HTMLNode results.\n            deliver_command (DeliverCommand): The DeliverCommand object that specifies how to deliver the results.\n\n        Usage:\n            ```python\n            Milkman().deliver(results, deliver_command)\n            ```\n\n        Warning:\n            Raises ScrapegoatIOException if the delivery to the specified destination fails.\n        \"\"\"\n        try:\n            deliver_command.execute(results)\n        except Exception as e:\n            raise ScrapegoatIOException(f\"Failed to save to file: {str(e)}\")\n        return\n\n    def receive(self, filepath: str) -&gt; str:\n        \"\"\"\n        Reads a goatspeak script from the specified file path.\n\n        Args:\n            filepath (str): The path to the goatspeak script file.\n\n        Returns:\n            str: The content of the goatspeak script file.\n\n        Usage:\n            ```python\n            goatspeak = Milkman().receive(\"path/to/script.goat\")\n            ```\n\n        Warning:\n            Raises ScrapegoatReadFileException if the file cannot be read.\n        \"\"\"\n        try:\n            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n                return f.read()\n        except Exception as e:\n            raise ScrapegoatIOException(f\"Failed to read goatspeak file at {filepath}: {str(e)}\")\n</code></pre>"},{"location":"core/classes/milkman/#scrapegoat_core.classes.milkman.Milkman.deliver","title":"<code>deliver(results, deliver_command)</code>","text":"<p>Delivers the scraped results using the specified DeliverCommand.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list</code> <p>A list of scraped HTMLNode results.</p> required <code>deliver_command</code> <code>DeliverCommand</code> <p>The DeliverCommand object that specifies how to deliver the results.</p> required Usage <pre><code>Milkman().deliver(results, deliver_command)\n</code></pre> Warning <p>Raises ScrapegoatIOException if the delivery to the specified destination fails.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/milkman.py</code> <pre><code>def deliver(self, results: list[\"HTMLNode\"], deliver_command: \"DeliverCommand\") -&gt; None: # type: ignore\n    \"\"\"\n    Delivers the scraped results using the specified DeliverCommand.\n\n    Args:\n        results (list): A list of scraped HTMLNode results.\n        deliver_command (DeliverCommand): The DeliverCommand object that specifies how to deliver the results.\n\n    Usage:\n        ```python\n        Milkman().deliver(results, deliver_command)\n        ```\n\n    Warning:\n        Raises ScrapegoatIOException if the delivery to the specified destination fails.\n    \"\"\"\n    try:\n        deliver_command.execute(results)\n    except Exception as e:\n        raise ScrapegoatIOException(f\"Failed to save to file: {str(e)}\")\n    return\n</code></pre>"},{"location":"core/classes/milkman/#scrapegoat_core.classes.milkman.Milkman.receive","title":"<code>receive(filepath)</code>","text":"<p>Reads a goatspeak script from the specified file path.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the goatspeak script file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The content of the goatspeak script file.</p> Usage <pre><code>goatspeak = Milkman().receive(\"path/to/script.goat\")\n</code></pre> Warning <p>Raises ScrapegoatReadFileException if the file cannot be read.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/milkman.py</code> <pre><code>def receive(self, filepath: str) -&gt; str:\n    \"\"\"\n    Reads a goatspeak script from the specified file path.\n\n    Args:\n        filepath (str): The path to the goatspeak script file.\n\n    Returns:\n        str: The content of the goatspeak script file.\n\n    Usage:\n        ```python\n        goatspeak = Milkman().receive(\"path/to/script.goat\")\n        ```\n\n    Warning:\n        Raises ScrapegoatReadFileException if the file cannot be read.\n    \"\"\"\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except Exception as e:\n        raise ScrapegoatIOException(f\"Failed to read goatspeak file at {filepath}: {str(e)}\")\n</code></pre>"},{"location":"core/classes/node/","title":"HTMLNode Class","text":""},{"location":"core/classes/node/#htmlnode","title":"HTMLNode","text":"<p>The HTMLNode is a data class used to represent an HTML element within the HTMLNode tree structure.</p> Info <p>Each HTMLNode instance corresponds to a single HTML element, encapsulating its tag type, attributes, text content, and relationships to other nodes in the tree (parent and children). The class provides methods for converting the node and its subtree into dictionary and HTML string representations, as well as methods for traversing and querying the tree structure. The HTMLNode is able to handle special extract instructions by modifying its representation through the to_dict() method.</p> <p>Attributes:</p> Name Type Description <code>VOID_TAGS</code> <code>set</code> <p>A set of HTML tag types that are considered void elements (self-closing tags).</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>class HTMLNode:\n    \"\"\"\n    The HTMLNode is a data class used to represent an HTML element within the HTMLNode tree structure.\n\n    Info:\n        Each HTMLNode instance corresponds to a single HTML element, encapsulating its tag type, attributes, text content, and relationships to other nodes in the tree (parent and children).\n        The class provides methods for converting the node and its subtree into dictionary and HTML string representations, as well as methods for traversing and querying the tree structure.\n        The HTMLNode is able to handle special extract instructions by modifying its representation through the to_dict() method.\n\n    Attributes:\n        VOID_TAGS (set): A set of HTML tag types that are considered void elements (self-closing tags).\n    \"\"\"\n    VOID_TAGS = {\"area\", \"base\", \"br\", \"col\", \"embed\", \"hr\", \"img\", \"input\", \"link\", \"meta\", \"param\", \"source\", \"track\", \"wbr\"}\n\n    def __init__(self, raw: str, tag_type: str, has_data: bool = False, html_attributes: dict[str, any] = None, body: str = \"\", parent=None):\n        \"\"\"\n        Initializes an instance of the HTMLNode class.\n\n        Args:\n            raw (str): The raw HTML string representing the element.\n            tag_type (str): The type of the HTML tag (e.g., 'div', 'span').\n            has_data (bool): Indicates whether the node contains text data. Defaults to False.\n            html_attributes (dict[str, any]): A dictionary of HTML attributes for the element. Defaults to None.\n            body (str): The text content within the HTML element. Defaults to an empty string.\n            parent (HTMLNode, optional): The parent HTMLNode of this node. Defaults to None for root nodes.\n        \"\"\"\n        self.id = str(uuid.uuid4())\n        self.raw = raw\n        self.tag_type = tag_type\n        self.has_data = has_data\n        self.html_attributes = {\"@\"+k: v for k, v in (html_attributes or {}).items()}\n        self.body = body\n        self.children = []\n        self.retrieval_instructions = \"\"\n        self.parent = parent\n        self.extract_fields = None\n        self.extract_flags = {\"ignore_children\": False, \"ignore_grandchildren\": False, \"table\": False}\n\n    def to_dict(self, ignore_children=False) -&gt; str:\n        \"\"\"\n        Converts the HTMLNode and its children into a dictionary representation.\n\n        Args:\n            ignore_children (bool): If True, child nodes will not be included in the dictionary representation. Defaults to False.\n\n        Returns:\n            dict: A dictionary representation of the HTMLNode.\n\n        Warning:\n            If the `table` extract flag is set to True while processing a non-table node, a GoatspeakInterpreterException will be raised.\n        \"\"\"\n        if self.extract_flags[\"table\"]:\n            if self.tag_type != \"table\":\n                raise GoatspeakInterpreterException(\"Table extraction requested on a non-table node\")\n            return self._handle_table_extract()\n        ignore_children = self.extract_flags[\"ignore_children\"] or ignore_children\n        for child in self.children:\n            child.set_extract_instructions(fields=self.extract_fields, ignore_children=self.extract_flags[\"ignore_grandchildren\"])\n        if self.extract_fields:\n            return self._handle_extract_fields(ignore_children)\n        if ignore_children:\n            return self._handle_ignore_children()\n        return {\n            \"id\": self.id,\n            \"raw\": self.raw,\n            \"tag_type\": self.tag_type,\n            \"has_data\": self.has_data,\n            \"html_attributes\": self.html_attributes,\n            \"body\": self.body,\n            \"children\": [child.to_dict() for child in self.children],\n            \"retrieval_instructions\": self.retrieval_instructions,\n            \"parent\": self.parent.id if self.parent else None,\n            \"extract_fields\": self.extract_fields,\n            \"extract_flags\": self.extract_flags,\n        }    \n\n    def _handle_extract_fields(self, ignore_children: bool) -&gt; dict  :\n        \"\"\"\n        \"\"\"\n        dict_representation = {}\n        for field in self.extract_fields:\n            if field[0] == \"@\":\n                dict_representation[field] = self.html_attributes.get(field, None)\n            else:\n                if field == \"id\":\n                    dict_representation[\"id\"] = self.id\n                elif field == \"tag_type\":\n                    dict_representation[\"tag_type\"] = self.tag_type\n                elif field == \"has_data\":\n                    dict_representation[\"has_data\"] = self.has_data\n                elif field == \"html_attributes\":\n                    dict_representation[\"html_attributes\"] = self.html_attributes\n                elif field == \"body\":\n                    dict_representation[\"body\"] = self.body\n                elif field == \"children\" and not ignore_children:\n                    dict_representation[\"children\"] = [child.to_dict() for child in self.children]\n                elif field == \"retrieval_instructions\":\n                    dict_representation[\"retrieval_instructions\"] = self.retrieval_instructions\n                elif field == \"parent\":\n                    dict_representation[\"parent\"] = self.parent.id if self.parent else None\n                elif field == \"extract_fields\":\n                    dict_representation[\"extract_fields\"] = self.extract_fields\n                elif field == \"extract_flags\":\n                    dict_representation[\"extract_flags\"] = self.extract_flags\n        return dict_representation\n\n    def _handle_ignore_children(self) -&gt; dict:\n        \"\"\"\n        \"\"\"\n        return {\n            \"id\": self.id,\n            \"raw\": self.raw,\n            \"tag_type\": self.tag_type,\n            \"has_data\": self.has_data,\n            \"html_attributes\": self.html_attributes,\n            \"body\": self.body,\n            \"retrieval_instructions\": self.retrieval_instructions,\n            \"parent\": self.parent.id if self.parent else None,\n            \"extract_fields\": self.extract_fields,\n            \"extract_flags\": self.extract_flags,\n        }\n\n    def _handle_table_extract(self) -&gt; list:\n        \"\"\"\n        Convert the &lt;table&gt; into a list of row JSON objects.\n        Each row is a dict: {header: cell_value}\n        \"\"\"\n        trows = self.get_descendants(tag_type=\"tr\")\n\n        if not trows:\n            return []\n\n        # Extract header row\n        header_row = trows[0]\n        headers = []\n\n        header_cells = (\n            header_row.get_descendants(tag_type=\"th\") +\n            header_row.get_descendants(tag_type=\"td\")\n        )\n\n        for cell in header_cells:\n            # Hoist descendant text\n            for child in cell.get_descendants():\n                cell.body += \" \" + child.body\n            headers.append(cell.body.strip())\n\n        # Extract data rows\n        result = []\n\n        for tr in trows[1:]:\n            cells = tr.get_descendants(tag_type=\"td\") + tr.get_descendants(tag_type=\"th\")\n            row = {}\n\n            for col_index, header in enumerate(headers):\n                if col_index &lt; len(cells):\n                    cell = cells[col_index]\n\n                    for child in cell.get_descendants():\n                        cell.body += \" \" + child.body\n\n                    row[header] = cell.body.strip()\n                else:\n                    row[header] = \"\"\n\n            result.append(row)\n        return result\n\n    def to_string(self) -&gt; str:\n        \"\"\"\n        Converts the HTMLNode to its string representation.\n\n        Returns:\n            str: The string representation of the HTMLNode.\n        \"\"\"\n        return str(self.to_dict())\n\n    def __repr__(self):\n        \"\"\"\n        \"\"\"\n        return self.to_string()\n\n    def to_html(self, indent=0) -&gt; str:\n        \"\"\"\n        Converts the HTMLNode and its children back into an HTML string.\n\n        Args:\n            indent (int): The indentation level for pretty-printing the HTML. Defaults to 0.\n\n        Returns:\n            str: The HTML string representation of the HTMLNode.\n        \"\"\"\n        html_attribute_string = \" \".join(f'{k}=\"{v}\"' for k, v in self.html_attributes.items())\n        if html_attribute_string:\n            opening = f\"&lt;{self.tag_type} {html_attribute_string}\"\n        else:\n            opening = f\"&lt;{self.tag_type}\"\n\n        if self.tag_type in self.VOID_TAGS:\n            opening += \" /&gt;\"\n        else:\n            opening += \"&gt;\"\n\n        text = f\" {self.body}\" if self.has_data else \"\"\n\n        pad = \"  \" * indent\n        result = f\"{pad}{opening}{text}\\n\"\n\n        for child in self.children:\n            result += child.to_html(indent + 1)\n\n        if self.tag_type not in self.VOID_TAGS:\n            result += f\"{pad}&lt;/{self.tag_type}&gt;\\n\"\n        return result\n\n    def __str__(self):\n        \"\"\"\n        \"\"\"\n        return self.to_string()\n\n    def get_parent(self) -&gt; \"HTMLNode\":\n        \"\"\"\n        Returns the parent HTMLNode.\n\n        Returns:\n            HTMLNode: The parent node.\n        \"\"\"\n        return self.parent\n\n    def get_children(self) -&gt; list[\"HTMLNode\"]:\n        \"\"\"\n        Returns the list of child HTMLNodes.\n\n        Returns:\n            list[HTMLNode]: The list of child nodes.\n        \"\"\"\n        return self.children\n\n    def get_ancestors(self) -&gt; list[\"HTMLNode\"]:\n        \"\"\"\n        Returns a list of ancestor HTMLNodes, starting from the immediate parent up to the root.\n\n        Returns:\n            list[HTMLNode]: A list of ancestor nodes.\n        \"\"\"\n        ancestors = []\n        current = self.parent\n        while current:\n            ancestors.append(current)\n            current = current.parent\n        return ancestors\n\n    def get_descendants(self, tag_type: str = None, **html_attributes) -&gt; list[\"HTMLNode\"]:\n        \"\"\"\n        Returns a list of descendant HTMLNodes that match the specified tag type and HTML attributes.\n\n        Args:\n            tag_type (str, optional): The tag type to filter descendants. If None, all tag types are included. Defaults to None.\n            **html_attributes: Key-value pairs of HTML attributes to filter descendants.\n\n        Returns:\n            list[HTMLNode]: A list of matching descendant nodes.\n        \"\"\"\n        descendants = []\n        for child in self.children:\n            if (tag_type is None or child.tag_type == tag_type) and all(child.html_attributes.get(k) == v for k, v in html_attributes.items()):\n                descendants.append(child)\n            descendants.extend(child.get_descendants(tag_type, **html_attributes))\n        return descendants\n\n    def preorder_traversal(self) -&gt; \"HTMLNode\": # type: ignore\n        \"\"\"\n        Generator that yields nodes in a preorder traversal of the HTMLNode tree.\n\n        Yields:\n            HTMLNode: The next node in the preorder traversal.\n        \"\"\"\n        yield self\n        for child in self.children:\n            yield from child.preorder_traversal()\n\n    def like_html_attribute(self, key, value=None) -&gt; bool:\n        \"\"\"\n        Uses a fuzzy match to check for the presence of an HTML attribute and its value.\n\n        Args:\n            key (str): The HTML attribute key to check.\n            value (str, optional): The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n        Returns:\n            bool: True if the attribute and value match, False otherwise.\n        \"\"\"\n        value = value.lower() if value is not None else value\n        if value is None:\n            return key in self.html_attributes\n        if self.html_attributes.get(key) is None:\n            return False\n        return value in str(self.html_attributes.get(key)).lower()\n\n    def has_html_attribute(self, key, value=None) -&gt; bool:\n        \"\"\"\n        Uses an exact match to check for the presence of an HTML attribute and its value.\n\n        Args:\n            key (str): The HTML attribute key to check.\n            value (str, optional): The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n        Returns:\n            bool: True if the attribute and value match, False otherwise.\n        \"\"\"\n        if value is None:\n            return key in self.html_attributes\n        if self.html_attributes.get(key) is None:\n            return False\n        return value == self.html_attributes.get(key)\n\n    def like_attribute(self, key, value=None) -&gt; bool:\n        \"\"\"\n        Uses a fuzzy match to check for the presence of a node attribute and its value.\n\n        Args:\n            key (str): The node attribute key to check.\n            value (str, optional): The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n        Returns:\n            bool: True if the attribute and value match, False otherwise.\n        \"\"\"\n        value = value.lower() if value is not None else value\n        if key == \"tag_type\":\n            if value is None:\n                return self.tag_type is not None\n            return value in self.tag_type.lower()\n        if key == \"id\":\n            if value is None:\n                return self.id is not None\n            return value in str(self.id).lower()\n        if key == \"has_data\":\n            if value is None:\n                return self.has_data\n            return str(value) == str(self.has_data).lower()\n        if key == \"body\":\n            if value is None:\n                return self.body is not None\n            return value in self.body.lower()\n        if key == \"retrieval_instructions\":\n            if value is None:\n                return self.retrieval_instructions is not None\n            return value in self.retrieval_instructions.lower()\n        if key == \"extract_fields\":\n            if value is None:\n                return self.extract_fields is not None\n            return self.extract_flags == value\n        if key == \"extract_flags\":\n            if value is None:\n                return self.extract_flags is not None\n            return self.extract_flags == value\n        if key == \"parent\":\n            if value is None:\n                return self.parent is not None\n            return self.parent and value in str(self.parent.id).lower()\n        if key == \"children\":\n            if value is None:\n                return len(self.children) &gt; 0\n            return any(value in str(child.id).lower() for child in self.children)\n        if key == \"raw\":\n            if value is None:\n                return self.raw is not None\n            return value in self.raw.lower()\n        return False\n\n    def has_attribute(self, key, value=None) -&gt; bool:\n        \"\"\"\n        Uses an exact match to check for the presence of a node attribute and its value.\n\n        Args:\n            key (str): The node attribute key to check.\n            value (str, optional): The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n        Returns:\n            bool: True if the attribute and value match, False otherwise.\n        \"\"\"\n        if key == \"tag_type\":\n            if value is None:\n                return self.tag_type is not None\n            return self.tag_type == value\n        if key == \"id\":\n            if value is None:\n                return self.id is not None\n            return str(self.id) == value\n        if key == \"has_data\":\n            if value is None:\n                return self.has_data\n            return self.has_data == value\n        if key == \"body\":\n            if value is None:\n                return self.body is not None\n            return self.body == value\n        if key == \"retrieval_instructions\":\n            if value is None:\n                return self.retrieval_instructions is not None\n            return self.retrieval_instructions == value\n        if key == \"extract_fields\":\n            if value is None:\n                return self.extract_fields is not None\n            return self.extract_fields == value\n        if key == \"extract_flags\":\n            if value is None:\n                return self.extract_flags is not None\n            return self.extract_flags == value\n        if key == \"parent\":\n            if value is None:\n                return self.parent is not None\n            return self.parent and str(self.parent.id) == value\n        if key == \"children\":\n            if value is None:\n                return len(self.children) &gt; 0\n            return any(str(child.id) == value for child in self.children)\n        if key == \"raw\":\n            if value is None:\n                return self.raw is not None\n            return self.raw == value\n        return False\n\n    def is_descendant_of(self, tag_type: str) -&gt; bool:\n        \"\"\"\n        Checks if the current node is a descendant of a node with the specified tag type.\n\n        Args:\n            tag_type (str): The tag type to check against.\n\n        Returns:\n            bool: True if the current node is a descendant of the specified tag type, False otherwise\n        \"\"\"\n        return any(ancestor.tag_type == tag_type for ancestor in self.get_ancestors())\n\n    def set_retrieval_instructions(self, instruction: str) -&gt; None:\n        \"\"\"\n        Sets the retrieval instructions for the HTMLNode.\n\n        Args:\n            instruction (str): The retrieval instruction string.\n        \"\"\"\n        self.retrieval_instructions = instruction\n\n    def set_extract_instructions(self, fields: list=None, ignore_children=False, ignore_grandchildren=False, table=False) -&gt; None:\n        \"\"\"\n        Sets the extraction instructions for the HTMLNode.\n\n        Args:\n            fields (list, optional): A list of fields to extract. If None, all fields will be extracted. Defaults to None.\n            ignore_children (bool): If True, child nodes will be ignored during extraction. Defaults to False.\n            ignore_grandchildren (bool): If True, grandchild nodes will be ignored during extraction. Defaults to False.\n            table (bool): If True, the node will be treated as a table for extraction. Defaults to False.\n        \"\"\"\n        self.extract_fields = fields or None\n        self.extract_flags = {\"ignore_children\": ignore_children, \"ignore_grandchildren\": ignore_grandchildren, \"table\": table}\n\n    def clear_extract_instructions(self) -&gt; None:\n        \"\"\"\n        Clears any extraction instructions set on the HTMLNode.\n        \"\"\"\n        self.extract_fields = None\n        self.extract_flags = None\n        self.table = False\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.__init__","title":"<code>__init__(raw, tag_type, has_data=False, html_attributes=None, body='', parent=None)</code>","text":"<p>Initializes an instance of the HTMLNode class.</p> <p>Parameters:</p> Name Type Description Default <code>raw</code> <code>str</code> <p>The raw HTML string representing the element.</p> required <code>tag_type</code> <code>str</code> <p>The type of the HTML tag (e.g., 'div', 'span').</p> required <code>has_data</code> <code>bool</code> <p>Indicates whether the node contains text data. Defaults to False.</p> <code>False</code> <code>html_attributes</code> <code>dict[str, any]</code> <p>A dictionary of HTML attributes for the element. Defaults to None.</p> <code>None</code> <code>body</code> <code>str</code> <p>The text content within the HTML element. Defaults to an empty string.</p> <code>''</code> <code>parent</code> <code>HTMLNode</code> <p>The parent HTMLNode of this node. Defaults to None for root nodes.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def __init__(self, raw: str, tag_type: str, has_data: bool = False, html_attributes: dict[str, any] = None, body: str = \"\", parent=None):\n    \"\"\"\n    Initializes an instance of the HTMLNode class.\n\n    Args:\n        raw (str): The raw HTML string representing the element.\n        tag_type (str): The type of the HTML tag (e.g., 'div', 'span').\n        has_data (bool): Indicates whether the node contains text data. Defaults to False.\n        html_attributes (dict[str, any]): A dictionary of HTML attributes for the element. Defaults to None.\n        body (str): The text content within the HTML element. Defaults to an empty string.\n        parent (HTMLNode, optional): The parent HTMLNode of this node. Defaults to None for root nodes.\n    \"\"\"\n    self.id = str(uuid.uuid4())\n    self.raw = raw\n    self.tag_type = tag_type\n    self.has_data = has_data\n    self.html_attributes = {\"@\"+k: v for k, v in (html_attributes or {}).items()}\n    self.body = body\n    self.children = []\n    self.retrieval_instructions = \"\"\n    self.parent = parent\n    self.extract_fields = None\n    self.extract_flags = {\"ignore_children\": False, \"ignore_grandchildren\": False, \"table\": False}\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.clear_extract_instructions","title":"<code>clear_extract_instructions()</code>","text":"<p>Clears any extraction instructions set on the HTMLNode.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def clear_extract_instructions(self) -&gt; None:\n    \"\"\"\n    Clears any extraction instructions set on the HTMLNode.\n    \"\"\"\n    self.extract_fields = None\n    self.extract_flags = None\n    self.table = False\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.get_ancestors","title":"<code>get_ancestors()</code>","text":"<p>Returns a list of ancestor HTMLNodes, starting from the immediate parent up to the root.</p> <p>Returns:</p> Type Description <code>list[HTMLNode]</code> <p>list[HTMLNode]: A list of ancestor nodes.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def get_ancestors(self) -&gt; list[\"HTMLNode\"]:\n    \"\"\"\n    Returns a list of ancestor HTMLNodes, starting from the immediate parent up to the root.\n\n    Returns:\n        list[HTMLNode]: A list of ancestor nodes.\n    \"\"\"\n    ancestors = []\n    current = self.parent\n    while current:\n        ancestors.append(current)\n        current = current.parent\n    return ancestors\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.get_children","title":"<code>get_children()</code>","text":"<p>Returns the list of child HTMLNodes.</p> <p>Returns:</p> Type Description <code>list[HTMLNode]</code> <p>list[HTMLNode]: The list of child nodes.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def get_children(self) -&gt; list[\"HTMLNode\"]:\n    \"\"\"\n    Returns the list of child HTMLNodes.\n\n    Returns:\n        list[HTMLNode]: The list of child nodes.\n    \"\"\"\n    return self.children\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.get_descendants","title":"<code>get_descendants(tag_type=None, **html_attributes)</code>","text":"<p>Returns a list of descendant HTMLNodes that match the specified tag type and HTML attributes.</p> <p>Parameters:</p> Name Type Description Default <code>tag_type</code> <code>str</code> <p>The tag type to filter descendants. If None, all tag types are included. Defaults to None.</p> <code>None</code> <code>**html_attributes</code> <p>Key-value pairs of HTML attributes to filter descendants.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[HTMLNode]</code> <p>list[HTMLNode]: A list of matching descendant nodes.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def get_descendants(self, tag_type: str = None, **html_attributes) -&gt; list[\"HTMLNode\"]:\n    \"\"\"\n    Returns a list of descendant HTMLNodes that match the specified tag type and HTML attributes.\n\n    Args:\n        tag_type (str, optional): The tag type to filter descendants. If None, all tag types are included. Defaults to None.\n        **html_attributes: Key-value pairs of HTML attributes to filter descendants.\n\n    Returns:\n        list[HTMLNode]: A list of matching descendant nodes.\n    \"\"\"\n    descendants = []\n    for child in self.children:\n        if (tag_type is None or child.tag_type == tag_type) and all(child.html_attributes.get(k) == v for k, v in html_attributes.items()):\n            descendants.append(child)\n        descendants.extend(child.get_descendants(tag_type, **html_attributes))\n    return descendants\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.get_parent","title":"<code>get_parent()</code>","text":"<p>Returns the parent HTMLNode.</p> <p>Returns:</p> Name Type Description <code>HTMLNode</code> <code>HTMLNode</code> <p>The parent node.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def get_parent(self) -&gt; \"HTMLNode\":\n    \"\"\"\n    Returns the parent HTMLNode.\n\n    Returns:\n        HTMLNode: The parent node.\n    \"\"\"\n    return self.parent\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.has_attribute","title":"<code>has_attribute(key, value=None)</code>","text":"<p>Uses an exact match to check for the presence of a node attribute and its value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The node attribute key to check.</p> required <code>value</code> <code>str</code> <p>The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attribute and value match, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def has_attribute(self, key, value=None) -&gt; bool:\n    \"\"\"\n    Uses an exact match to check for the presence of a node attribute and its value.\n\n    Args:\n        key (str): The node attribute key to check.\n        value (str, optional): The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n    Returns:\n        bool: True if the attribute and value match, False otherwise.\n    \"\"\"\n    if key == \"tag_type\":\n        if value is None:\n            return self.tag_type is not None\n        return self.tag_type == value\n    if key == \"id\":\n        if value is None:\n            return self.id is not None\n        return str(self.id) == value\n    if key == \"has_data\":\n        if value is None:\n            return self.has_data\n        return self.has_data == value\n    if key == \"body\":\n        if value is None:\n            return self.body is not None\n        return self.body == value\n    if key == \"retrieval_instructions\":\n        if value is None:\n            return self.retrieval_instructions is not None\n        return self.retrieval_instructions == value\n    if key == \"extract_fields\":\n        if value is None:\n            return self.extract_fields is not None\n        return self.extract_fields == value\n    if key == \"extract_flags\":\n        if value is None:\n            return self.extract_flags is not None\n        return self.extract_flags == value\n    if key == \"parent\":\n        if value is None:\n            return self.parent is not None\n        return self.parent and str(self.parent.id) == value\n    if key == \"children\":\n        if value is None:\n            return len(self.children) &gt; 0\n        return any(str(child.id) == value for child in self.children)\n    if key == \"raw\":\n        if value is None:\n            return self.raw is not None\n        return self.raw == value\n    return False\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.has_html_attribute","title":"<code>has_html_attribute(key, value=None)</code>","text":"<p>Uses an exact match to check for the presence of an HTML attribute and its value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The HTML attribute key to check.</p> required <code>value</code> <code>str</code> <p>The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attribute and value match, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def has_html_attribute(self, key, value=None) -&gt; bool:\n    \"\"\"\n    Uses an exact match to check for the presence of an HTML attribute and its value.\n\n    Args:\n        key (str): The HTML attribute key to check.\n        value (str, optional): The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n    Returns:\n        bool: True if the attribute and value match, False otherwise.\n    \"\"\"\n    if value is None:\n        return key in self.html_attributes\n    if self.html_attributes.get(key) is None:\n        return False\n    return value == self.html_attributes.get(key)\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.is_descendant_of","title":"<code>is_descendant_of(tag_type)</code>","text":"<p>Checks if the current node is a descendant of a node with the specified tag type.</p> <p>Parameters:</p> Name Type Description Default <code>tag_type</code> <code>str</code> <p>The tag type to check against.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the current node is a descendant of the specified tag type, False otherwise</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def is_descendant_of(self, tag_type: str) -&gt; bool:\n    \"\"\"\n    Checks if the current node is a descendant of a node with the specified tag type.\n\n    Args:\n        tag_type (str): The tag type to check against.\n\n    Returns:\n        bool: True if the current node is a descendant of the specified tag type, False otherwise\n    \"\"\"\n    return any(ancestor.tag_type == tag_type for ancestor in self.get_ancestors())\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.like_attribute","title":"<code>like_attribute(key, value=None)</code>","text":"<p>Uses a fuzzy match to check for the presence of a node attribute and its value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The node attribute key to check.</p> required <code>value</code> <code>str</code> <p>The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attribute and value match, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def like_attribute(self, key, value=None) -&gt; bool:\n    \"\"\"\n    Uses a fuzzy match to check for the presence of a node attribute and its value.\n\n    Args:\n        key (str): The node attribute key to check.\n        value (str, optional): The node attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n    Returns:\n        bool: True if the attribute and value match, False otherwise.\n    \"\"\"\n    value = value.lower() if value is not None else value\n    if key == \"tag_type\":\n        if value is None:\n            return self.tag_type is not None\n        return value in self.tag_type.lower()\n    if key == \"id\":\n        if value is None:\n            return self.id is not None\n        return value in str(self.id).lower()\n    if key == \"has_data\":\n        if value is None:\n            return self.has_data\n        return str(value) == str(self.has_data).lower()\n    if key == \"body\":\n        if value is None:\n            return self.body is not None\n        return value in self.body.lower()\n    if key == \"retrieval_instructions\":\n        if value is None:\n            return self.retrieval_instructions is not None\n        return value in self.retrieval_instructions.lower()\n    if key == \"extract_fields\":\n        if value is None:\n            return self.extract_fields is not None\n        return self.extract_flags == value\n    if key == \"extract_flags\":\n        if value is None:\n            return self.extract_flags is not None\n        return self.extract_flags == value\n    if key == \"parent\":\n        if value is None:\n            return self.parent is not None\n        return self.parent and value in str(self.parent.id).lower()\n    if key == \"children\":\n        if value is None:\n            return len(self.children) &gt; 0\n        return any(value in str(child.id).lower() for child in self.children)\n    if key == \"raw\":\n        if value is None:\n            return self.raw is not None\n        return value in self.raw.lower()\n    return False\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.like_html_attribute","title":"<code>like_html_attribute(key, value=None)</code>","text":"<p>Uses a fuzzy match to check for the presence of an HTML attribute and its value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The HTML attribute key to check.</p> required <code>value</code> <code>str</code> <p>The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attribute and value match, False otherwise.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def like_html_attribute(self, key, value=None) -&gt; bool:\n    \"\"\"\n    Uses a fuzzy match to check for the presence of an HTML attribute and its value.\n\n    Args:\n        key (str): The HTML attribute key to check.\n        value (str, optional): The HTML attribute value to check. If None, only the presence of the key is checked. Defaults to None.\n\n    Returns:\n        bool: True if the attribute and value match, False otherwise.\n    \"\"\"\n    value = value.lower() if value is not None else value\n    if value is None:\n        return key in self.html_attributes\n    if self.html_attributes.get(key) is None:\n        return False\n    return value in str(self.html_attributes.get(key)).lower()\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.preorder_traversal","title":"<code>preorder_traversal()</code>","text":"<p>Generator that yields nodes in a preorder traversal of the HTMLNode tree.</p> <p>Yields:</p> Name Type Description <code>HTMLNode</code> <code>HTMLNode</code> <p>The next node in the preorder traversal.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def preorder_traversal(self) -&gt; \"HTMLNode\": # type: ignore\n    \"\"\"\n    Generator that yields nodes in a preorder traversal of the HTMLNode tree.\n\n    Yields:\n        HTMLNode: The next node in the preorder traversal.\n    \"\"\"\n    yield self\n    for child in self.children:\n        yield from child.preorder_traversal()\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.set_extract_instructions","title":"<code>set_extract_instructions(fields=None, ignore_children=False, ignore_grandchildren=False, table=False)</code>","text":"<p>Sets the extraction instructions for the HTMLNode.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>list</code> <p>A list of fields to extract. If None, all fields will be extracted. Defaults to None.</p> <code>None</code> <code>ignore_children</code> <code>bool</code> <p>If True, child nodes will be ignored during extraction. Defaults to False.</p> <code>False</code> <code>ignore_grandchildren</code> <code>bool</code> <p>If True, grandchild nodes will be ignored during extraction. Defaults to False.</p> <code>False</code> <code>table</code> <code>bool</code> <p>If True, the node will be treated as a table for extraction. Defaults to False.</p> <code>False</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def set_extract_instructions(self, fields: list=None, ignore_children=False, ignore_grandchildren=False, table=False) -&gt; None:\n    \"\"\"\n    Sets the extraction instructions for the HTMLNode.\n\n    Args:\n        fields (list, optional): A list of fields to extract. If None, all fields will be extracted. Defaults to None.\n        ignore_children (bool): If True, child nodes will be ignored during extraction. Defaults to False.\n        ignore_grandchildren (bool): If True, grandchild nodes will be ignored during extraction. Defaults to False.\n        table (bool): If True, the node will be treated as a table for extraction. Defaults to False.\n    \"\"\"\n    self.extract_fields = fields or None\n    self.extract_flags = {\"ignore_children\": ignore_children, \"ignore_grandchildren\": ignore_grandchildren, \"table\": table}\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.set_retrieval_instructions","title":"<code>set_retrieval_instructions(instruction)</code>","text":"<p>Sets the retrieval instructions for the HTMLNode.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>The retrieval instruction string.</p> required Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def set_retrieval_instructions(self, instruction: str) -&gt; None:\n    \"\"\"\n    Sets the retrieval instructions for the HTMLNode.\n\n    Args:\n        instruction (str): The retrieval instruction string.\n    \"\"\"\n    self.retrieval_instructions = instruction\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.to_dict","title":"<code>to_dict(ignore_children=False)</code>","text":"<p>Converts the HTMLNode and its children into a dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>ignore_children</code> <code>bool</code> <p>If True, child nodes will not be included in the dictionary representation. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>str</code> <p>A dictionary representation of the HTMLNode.</p> Warning <p>If the <code>table</code> extract flag is set to True while processing a non-table node, a GoatspeakInterpreterException will be raised.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def to_dict(self, ignore_children=False) -&gt; str:\n    \"\"\"\n    Converts the HTMLNode and its children into a dictionary representation.\n\n    Args:\n        ignore_children (bool): If True, child nodes will not be included in the dictionary representation. Defaults to False.\n\n    Returns:\n        dict: A dictionary representation of the HTMLNode.\n\n    Warning:\n        If the `table` extract flag is set to True while processing a non-table node, a GoatspeakInterpreterException will be raised.\n    \"\"\"\n    if self.extract_flags[\"table\"]:\n        if self.tag_type != \"table\":\n            raise GoatspeakInterpreterException(\"Table extraction requested on a non-table node\")\n        return self._handle_table_extract()\n    ignore_children = self.extract_flags[\"ignore_children\"] or ignore_children\n    for child in self.children:\n        child.set_extract_instructions(fields=self.extract_fields, ignore_children=self.extract_flags[\"ignore_grandchildren\"])\n    if self.extract_fields:\n        return self._handle_extract_fields(ignore_children)\n    if ignore_children:\n        return self._handle_ignore_children()\n    return {\n        \"id\": self.id,\n        \"raw\": self.raw,\n        \"tag_type\": self.tag_type,\n        \"has_data\": self.has_data,\n        \"html_attributes\": self.html_attributes,\n        \"body\": self.body,\n        \"children\": [child.to_dict() for child in self.children],\n        \"retrieval_instructions\": self.retrieval_instructions,\n        \"parent\": self.parent.id if self.parent else None,\n        \"extract_fields\": self.extract_fields,\n        \"extract_flags\": self.extract_flags,\n    }    \n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.to_html","title":"<code>to_html(indent=0)</code>","text":"<p>Converts the HTMLNode and its children back into an HTML string.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int</code> <p>The indentation level for pretty-printing the HTML. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The HTML string representation of the HTMLNode.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def to_html(self, indent=0) -&gt; str:\n    \"\"\"\n    Converts the HTMLNode and its children back into an HTML string.\n\n    Args:\n        indent (int): The indentation level for pretty-printing the HTML. Defaults to 0.\n\n    Returns:\n        str: The HTML string representation of the HTMLNode.\n    \"\"\"\n    html_attribute_string = \" \".join(f'{k}=\"{v}\"' for k, v in self.html_attributes.items())\n    if html_attribute_string:\n        opening = f\"&lt;{self.tag_type} {html_attribute_string}\"\n    else:\n        opening = f\"&lt;{self.tag_type}\"\n\n    if self.tag_type in self.VOID_TAGS:\n        opening += \" /&gt;\"\n    else:\n        opening += \"&gt;\"\n\n    text = f\" {self.body}\" if self.has_data else \"\"\n\n    pad = \"  \" * indent\n    result = f\"{pad}{opening}{text}\\n\"\n\n    for child in self.children:\n        result += child.to_html(indent + 1)\n\n    if self.tag_type not in self.VOID_TAGS:\n        result += f\"{pad}&lt;/{self.tag_type}&gt;\\n\"\n    return result\n</code></pre>"},{"location":"core/classes/node/#scrapegoat_core.classes.node.HTMLNode.to_string","title":"<code>to_string()</code>","text":"<p>Converts the HTMLNode to its string representation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The string representation of the HTMLNode.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/node.py</code> <pre><code>def to_string(self) -&gt; str:\n    \"\"\"\n    Converts the HTMLNode to its string representation.\n\n    Returns:\n        str: The string representation of the HTMLNode.\n    \"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"core/classes/sheepdog/","title":"Sheepdog Classes","text":""},{"location":"core/classes/sheepdog/#sheepdog","title":"Sheepdog","text":"<p>The Sheepdog class is responsible for fetching HTML content from the web. By default, it uses the requests library to perform HTTP GET requests, and has its own default headers to mimic a standard web browser.</p> Hint <p>This is one of Scrapegoat's highly extendable classes. You can extend this class to implement custom fetching behavior, such as using headless browsers or handling specific authentication mechanisms. Alternatively, a custom getter function can be passed into the constructor to override the default fetching behavior.</p> <p>Attributes:</p> Name Type Description <code>DEFAULT_HEADERS</code> <code>dict</code> <p>A dictionary of default HTTP headers to use for requests.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>class Sheepdog:\n    \"\"\"\n    The Sheepdog class is responsible for fetching HTML content from the web. By default, it uses the requests library to perform HTTP GET requests, and has its own default headers to mimic a standard web browser.\n\n    Hint:\n        This is one of Scrapegoat's highly extendable classes. You can extend this class to implement custom fetching behavior, such as using headless browsers or handling specific authentication mechanisms. Alternatively, a custom getter function can be passed into the constructor to override the default fetching behavior.\n\n    Attributes:\n        DEFAULT_HEADERS (dict): A dictionary of default HTTP headers to use for requests.\n    \"\"\"\n    DEFAULT_HEADERS = {\n        \"User-Agent\": \"Mozilla/5.0 (Scrapegoat)\",\n        \"Accept-Language\": \"en-US,en;q=0.9\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Connection\": \"keep-alive\",\n        \"Accept\": \"*/*\",\n        \"DNT\": \"1\",\n        \"Upgrade-Insecure-Requests\": \"1\",\n        \"Sec-Fetch-Dest\": \"document\",\n        \"Sec-Fetch-Mode\": \"navigate\",\n    }\n\n    def __init__(self, getter: callable=None):\n        \"\"\"\n        Initializes an instance of the Sheepdog class. Accepts an optional custom getter function. \n\n        Args:\n            getter (callable, optional): A custom function to fetch HTML content. Defaults to None, which uses the default getter method.\n        \"\"\"\n        self.getter = getter or self.getter\n\n    def fetch(self, fetch_command: Union[str, FetchCommand]) -&gt; str:\n        \"\"\"\n        Fetches HTML content using the provided fetch command or URL string.\n\n        Args:\n            fetch_command (Union[str, FetchCommand]): A FetchCommand object or a URL string to fetch HTML content from.\n\n        Returns:\n            str: The fetched HTML content.\n\n        Usage:\n            ```python\n            html_content = Sheepdog().fetch(\"http://example.com\")\n            ```\n        \"\"\"\n        if not isinstance(fetch_command, FetchCommand):\n            fetch_command = FetchCommand(fetch_command)\n        fetch_command.set_getter(self.getter)\n        return fetch_command.execute()\n\n    def getter(self, url: str, **kwargs) -&gt; str:\n        \"\"\"\n        Fetches HTML content from the given URL using the requests library.\n\n        Args:\n            url (str): The URL to fetch HTML content from.\n            **kwargs: Additional keyword arguments to pass to the requests.get() method.\n\n        Returns:\n            str: The fetched HTML content.\n\n        Warning:\n            Raises ScrapegoatFetchException if the fetch operation fails.\n        \"\"\"\n        try:\n            headers = kwargs.pop('headers', self.DEFAULT_HEADERS)\n            response = requests.get(url, headers=headers, **kwargs)\n            response.raise_for_status()\n            return response.text\n        except Exception as e:\n            raise ScrapegoatFetchException(f\"Failed to fetch URL {url}: {str(e)}\")\n</code></pre>"},{"location":"core/classes/sheepdog/#scrapegoat_core.classes.sheepdog.Sheepdog.__init__","title":"<code>__init__(getter=None)</code>","text":"<p>Initializes an instance of the Sheepdog class. Accepts an optional custom getter function. </p> <p>Parameters:</p> Name Type Description Default <code>getter</code> <code>callable</code> <p>A custom function to fetch HTML content. Defaults to None, which uses the default getter method.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>def __init__(self, getter: callable=None):\n    \"\"\"\n    Initializes an instance of the Sheepdog class. Accepts an optional custom getter function. \n\n    Args:\n        getter (callable, optional): A custom function to fetch HTML content. Defaults to None, which uses the default getter method.\n    \"\"\"\n    self.getter = getter or self.getter\n</code></pre>"},{"location":"core/classes/sheepdog/#scrapegoat_core.classes.sheepdog.Sheepdog.fetch","title":"<code>fetch(fetch_command)</code>","text":"<p>Fetches HTML content using the provided fetch command or URL string.</p> <p>Parameters:</p> Name Type Description Default <code>fetch_command</code> <code>Union[str, FetchCommand]</code> <p>A FetchCommand object or a URL string to fetch HTML content from.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The fetched HTML content.</p> Usage <pre><code>html_content = Sheepdog().fetch(\"http://example.com\")\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>def fetch(self, fetch_command: Union[str, FetchCommand]) -&gt; str:\n    \"\"\"\n    Fetches HTML content using the provided fetch command or URL string.\n\n    Args:\n        fetch_command (Union[str, FetchCommand]): A FetchCommand object or a URL string to fetch HTML content from.\n\n    Returns:\n        str: The fetched HTML content.\n\n    Usage:\n        ```python\n        html_content = Sheepdog().fetch(\"http://example.com\")\n        ```\n    \"\"\"\n    if not isinstance(fetch_command, FetchCommand):\n        fetch_command = FetchCommand(fetch_command)\n    fetch_command.set_getter(self.getter)\n    return fetch_command.execute()\n</code></pre>"},{"location":"core/classes/sheepdog/#scrapegoat_core.classes.sheepdog.Sheepdog.getter","title":"<code>getter(url, **kwargs)</code>","text":"<p>Fetches HTML content from the given URL using the requests library.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to fetch HTML content from.</p> required <code>**kwargs</code> <p>Additional keyword arguments to pass to the requests.get() method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The fetched HTML content.</p> Warning <p>Raises ScrapegoatFetchException if the fetch operation fails.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>def getter(self, url: str, **kwargs) -&gt; str:\n    \"\"\"\n    Fetches HTML content from the given URL using the requests library.\n\n    Args:\n        url (str): The URL to fetch HTML content from.\n        **kwargs: Additional keyword arguments to pass to the requests.get() method.\n\n    Returns:\n        str: The fetched HTML content.\n\n    Warning:\n        Raises ScrapegoatFetchException if the fetch operation fails.\n    \"\"\"\n    try:\n        headers = kwargs.pop('headers', self.DEFAULT_HEADERS)\n        response = requests.get(url, headers=headers, **kwargs)\n        response.raise_for_status()\n        return response.text\n    except Exception as e:\n        raise ScrapegoatFetchException(f\"Failed to fetch URL {url}: {str(e)}\")\n</code></pre>"},{"location":"core/classes/sheepdog/#headlesssheepdog","title":"HeadlessSheepdog","text":"<p>               Bases: <code>Sheepdog</code></p> <p>The HeadlessSheepdog class extends the Sheepdog class to fetch HTML content using a headless browser via the Playwright library. This class uses a very simple implementation that will wait for the DOM content to load before returning the HTML.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>class HeadlessSheepdog(Sheepdog):\n    \"\"\"\n    The HeadlessSheepdog class extends the Sheepdog class to fetch HTML content using a headless browser via the Playwright library. This class uses a very simple implementation that will wait for the DOM content to load before returning the HTML.\n    \"\"\"\n    def __init__(self, getter=None):\n        \"\"\"\n        Initializes an instance of the HeadlessSheepdog class. Accepts an optional custom getter function.\n\n        Args:\n            getter (callable, optional): A custom function to fetch HTML content. Defaults to None, which uses the default Playwright-based getter method.\n        \"\"\"\n        super().__init__(getter)\n\n    def getter(self, url: str, **kwargs) -&gt; str:\n        \"\"\"\n        Fetches HTML content from the given URL using a headless browser via Playwright.\n\n        Args:\n            url (str): The URL to fetch HTML content from.\n            **kwargs: Additional keyword arguments (not used in this implementation).\n\n        Returns:\n            str: The fetched HTML content.\n\n        Usage:\n            ```python\n            html_content = HeadlessSheepdog().fetch(\"http://example.com\")\n            ```\n\n        Warning:\n            The Playwright library must be installed separately. If it is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install Playwright, run 'pip install playwright' in your terminal.\n\n        Warning:\n            A headless browser must be installed on the local device. If one is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install the executables, run 'playwright install' in your terminal.\n\n        Warning:\n            Raises ScrapegoatFetchException if the fetch operation fails.\n        \"\"\"\n        try:\n            from playwright.sync_api import sync_playwright\n        except ImportError:\n            raise ScrapegoatPlaywrightException(\"Playwright is not installed. Please install it with 'pip install playwright'\")\n\n        try:\n            with sync_playwright() as p:\n                browser = p.chromium.launch(headless=True)\n                page = browser.new_page()\n                page.goto(url, wait_until=\"domcontentloaded\")\n                return page.content()\n        except Exception as e:\n            if \"Executable doesn't exist\" in str(e):\n                raise ScrapegoatPlaywrightException(\"Playwright browser executables are not installed. Please run 'playwright install' to install them.\")\n            else:\n                raise ScrapegoatFetchException(f\"Failed to fetch URL {url} using Playwright: {str(e)}\")\n</code></pre>"},{"location":"core/classes/sheepdog/#scrapegoat_core.classes.sheepdog.HeadlessSheepdog.__init__","title":"<code>__init__(getter=None)</code>","text":"<p>Initializes an instance of the HeadlessSheepdog class. Accepts an optional custom getter function.</p> <p>Parameters:</p> Name Type Description Default <code>getter</code> <code>callable</code> <p>A custom function to fetch HTML content. Defaults to None, which uses the default Playwright-based getter method.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>def __init__(self, getter=None):\n    \"\"\"\n    Initializes an instance of the HeadlessSheepdog class. Accepts an optional custom getter function.\n\n    Args:\n        getter (callable, optional): A custom function to fetch HTML content. Defaults to None, which uses the default Playwright-based getter method.\n    \"\"\"\n    super().__init__(getter)\n</code></pre>"},{"location":"core/classes/sheepdog/#scrapegoat_core.classes.sheepdog.HeadlessSheepdog.getter","title":"<code>getter(url, **kwargs)</code>","text":"<p>Fetches HTML content from the given URL using a headless browser via Playwright.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to fetch HTML content from.</p> required <code>**kwargs</code> <p>Additional keyword arguments (not used in this implementation).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The fetched HTML content.</p> Usage <pre><code>html_content = HeadlessSheepdog().fetch(\"http://example.com\")\n</code></pre> Warning <p>The Playwright library must be installed separately. If it is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install Playwright, run 'pip install playwright' in your terminal.</p> Warning <p>A headless browser must be installed on the local device. If one is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install the executables, run 'playwright install' in your terminal.</p> Warning <p>Raises ScrapegoatFetchException if the fetch operation fails.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/sheepdog.py</code> <pre><code>def getter(self, url: str, **kwargs) -&gt; str:\n    \"\"\"\n    Fetches HTML content from the given URL using a headless browser via Playwright.\n\n    Args:\n        url (str): The URL to fetch HTML content from.\n        **kwargs: Additional keyword arguments (not used in this implementation).\n\n    Returns:\n        str: The fetched HTML content.\n\n    Usage:\n        ```python\n        html_content = HeadlessSheepdog().fetch(\"http://example.com\")\n        ```\n\n    Warning:\n        The Playwright library must be installed separately. If it is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install Playwright, run 'pip install playwright' in your terminal.\n\n    Warning:\n        A headless browser must be installed on the local device. If one is not installed, a ScrapegoatPlaywrightException will be raised when attempting to fetch content. To install the executables, run 'playwright install' in your terminal.\n\n    Warning:\n        Raises ScrapegoatFetchException if the fetch operation fails.\n    \"\"\"\n    try:\n        from playwright.sync_api import sync_playwright\n    except ImportError:\n        raise ScrapegoatPlaywrightException(\"Playwright is not installed. Please install it with 'pip install playwright'\")\n\n    try:\n        with sync_playwright() as p:\n            browser = p.chromium.launch(headless=True)\n            page = browser.new_page()\n            page.goto(url, wait_until=\"domcontentloaded\")\n            return page.content()\n    except Exception as e:\n        if \"Executable doesn't exist\" in str(e):\n            raise ScrapegoatPlaywrightException(\"Playwright browser executables are not installed. Please run 'playwright install' to install them.\")\n        else:\n            raise ScrapegoatFetchException(f\"Failed to fetch URL {url} using Playwright: {str(e)}\")\n</code></pre>"},{"location":"core/classes/shepherd/","title":"Shepherd Class","text":""},{"location":"core/classes/shepherd/#shepherd","title":"Shepherd","text":"<p>The master class that orchestrates the query to data scraping process. This class delegates its job to subclasses like the Gardener, Sheepdog, Goat, Milkmaid, and Milkman. All subclasses can be extended and passed into the Shepherd constructor to customize its behavior.</p> <p>Users should primarily interact with this class to perform webscraping with Scrapegoat. It exposes methods to execute goatspeak queries from strings or files, starting from URLs, raw HTML, or existing HTMLNode trees.</p> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>class Shepherd:\n    \"\"\"\n    The master class that orchestrates the query to data scraping process. This class delegates its job to subclasses like the Gardener, Sheepdog, Goat, Milkmaid, and Milkman. All subclasses can be extended and passed into the Shepherd constructor to customize its behavior.\n\n    Users should primarily interact with this class to perform webscraping with Scrapegoat. It exposes methods to execute goatspeak queries from strings or files, starting from URLs, raw HTML, or existing HTMLNode trees.\n    \"\"\"\n    def __init__(self, gardener:Gardener=None, sheepdog:Sheepdog=None, goat:Goat=None, milkmaid:Milkmaid=None, milkman:Milkman=None):\n        \"\"\"\n        The Shepherd class constructor.\n\n        Args:\n            gardener (Gardener, optional): An instance of the Gardener class. Defaults to a new Gardener instance.\n            sheepdog (Sheepdog, optional): An instance of the Sheepdog class. Defaults to a new Sheepdog instance.\n            goat (Goat, optional): An instance of the Goat class. Defaults to a new Goat instance.\n            milkmaid (Milkmaid, optional): An instance of the Milkmaid class. Defaults to a new Milkmaid instance.\n            milkman (Milkman, optional): An instance of the Milkman class. Defaults to a new Milkman instance.\n        \"\"\"\n        self.gardener = gardener if gardener else Gardener()\n        self.interpreter = Interpreter()\n        self.sheepdog = sheepdog if sheepdog else Sheepdog()\n        self.goat = goat if goat else Goat()\n        self.milkmaid = milkmaid if milkmaid else Milkmaid()\n        self.milkman = milkman if milkman else Milkman()\n\n    def herd(self, query: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Executes the full data scraping process based on the provided goatspeak query. Accepts either a goatspeak string or a file path to a goatspeak file.\n\n        Args:\n            query (str): A goatspeak string or a file path to a goatspeak file.\n\n        Returns:\n            list: A list of scraped HTMLNode results.\n\n        Usage:\n            ```python\n            results = Shepherd().herd(\"VISIT 'http://example.com'; SCRAPE 1 p;\")\n            ```\n        \"\"\"\n        goatspeak = self._convert_query_to_goatspeak(query)\n\n        results = []\n\n        for block in goatspeak:\n            html = self.sheepdog.fetch(block.fetch_command)\n            root = self.gardener.grow_tree(html)\n            self._query_list_handler(block.query_list, root, results)\n\n        return list(dict.fromkeys(results))\n\n    def _convert_query_to_goatspeak(self, query: str) -&gt; None:\n        \"\"\"\n        \"\"\"\n        if os.path.isfile(query):\n            try:\n                return self.interpreter.interpret(self.milkman.receive(query))\n            except Exception as e:\n                raise e\n        try:\n            return self.interpreter.interpret(query)\n        except Exception as e:\n            raise e                \n\n    def _query_list_handler(self, query_list: str, root, results) -&gt; list:\n        \"\"\"\n        \"\"\"\n        for query in query_list:\n            query_results = (self.goat.feast(root, query.graze_commands))\n            if query.churn_command:\n                self.milkmaid.churn(query_results, query.churn_command)\n\n            results.extend(query_results)\n\n            if query.deliver_command:\n                self.milkman.deliver(results, query.deliver_command)\n                results.clear()\n        return\n\n    def _local_herd(self, query: str, root) -&gt; list:\n        \"\"\"\n        \"\"\"\n        goatspeak = self._convert_query_to_goatspeak(query)\n\n        results = []\n\n        for block in goatspeak:\n            self._query_list_handler(block.query_list, root, results)\n\n        return list(dict.fromkeys(results))\n\n    def herd_from_node(self, query: str, root: \"HTMLNode\") -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Executes a goatspeak query starting from a given HTMLNode.\n\n        Args:\n            query (str): A goatspeak string or a file path to a goatspeak file.\n            root (HTMLNode): The starting HTMLNode from which to execute the query.\n\n        Returns:\n            list: A list of scraped HTMLNode results.\n\n        Usage:\n            ```python\n            root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\n            results = Shepherd().herd_from_node(\"SCRAPE 1 p;\", root_node)\n            ```\n        \"\"\"\n        return self._local_herd(query, root=root)\n\n    def herd_from_html(self, query: str, html: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Grows an HTMLNode tree from raw HTML and executes a goatspeak query on it.\n\n        Args:\n            query (str): A goatspeak string or a file path to a goatspeak file.\n            html (str): The raw HTML string to be parsed.\n\n        Returns:\n            list: A list of scraped HTMLNode results.\n\n        Usage:\n            ```python\n            html_content = \"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\"\n            results = Shepherd().herd_from_html(\"SCRAPE 1 p;\", html_content)\n            ```\n        \"\"\"\n        root = self.gardener.grow_tree(html)\n        return self._local_herd(query, root=root)\n\n    def herd_from_url(self, query: str, url: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n        \"\"\"\n        Fetches HTML from a URL, grows an HTMLNode tree, and executes a goatspeak query on it.\n\n        Args:\n            query (str): A goatspeak string or a file path to a goatspeak file.\n            url (str): The URL from which to fetch HTML content.\n\n        Returns:\n            list: A list of scraped HTMLNode results.\n\n        Usage:\n            ```python\n            results = Shepherd().herd_from_url(\"SCRAPE 1 p;\", \"http://example.com\")\n            ```\n        \"\"\"\n        html = self.sheepdog.fetch(url)\n        root = self.gardener.grow_tree(html)\n        return self._local_herd(query, root=root)\n</code></pre>"},{"location":"core/classes/shepherd/#scrapegoat_core.classes.shepherd.Shepherd.__init__","title":"<code>__init__(gardener=None, sheepdog=None, goat=None, milkmaid=None, milkman=None)</code>","text":"<p>The Shepherd class constructor.</p> <p>Parameters:</p> Name Type Description Default <code>gardener</code> <code>Gardener</code> <p>An instance of the Gardener class. Defaults to a new Gardener instance.</p> <code>None</code> <code>sheepdog</code> <code>Sheepdog</code> <p>An instance of the Sheepdog class. Defaults to a new Sheepdog instance.</p> <code>None</code> <code>goat</code> <code>Goat</code> <p>An instance of the Goat class. Defaults to a new Goat instance.</p> <code>None</code> <code>milkmaid</code> <code>Milkmaid</code> <p>An instance of the Milkmaid class. Defaults to a new Milkmaid instance.</p> <code>None</code> <code>milkman</code> <code>Milkman</code> <p>An instance of the Milkman class. Defaults to a new Milkman instance.</p> <code>None</code> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>def __init__(self, gardener:Gardener=None, sheepdog:Sheepdog=None, goat:Goat=None, milkmaid:Milkmaid=None, milkman:Milkman=None):\n    \"\"\"\n    The Shepherd class constructor.\n\n    Args:\n        gardener (Gardener, optional): An instance of the Gardener class. Defaults to a new Gardener instance.\n        sheepdog (Sheepdog, optional): An instance of the Sheepdog class. Defaults to a new Sheepdog instance.\n        goat (Goat, optional): An instance of the Goat class. Defaults to a new Goat instance.\n        milkmaid (Milkmaid, optional): An instance of the Milkmaid class. Defaults to a new Milkmaid instance.\n        milkman (Milkman, optional): An instance of the Milkman class. Defaults to a new Milkman instance.\n    \"\"\"\n    self.gardener = gardener if gardener else Gardener()\n    self.interpreter = Interpreter()\n    self.sheepdog = sheepdog if sheepdog else Sheepdog()\n    self.goat = goat if goat else Goat()\n    self.milkmaid = milkmaid if milkmaid else Milkmaid()\n    self.milkman = milkman if milkman else Milkman()\n</code></pre>"},{"location":"core/classes/shepherd/#scrapegoat_core.classes.shepherd.Shepherd.herd","title":"<code>herd(query)</code>","text":"<p>Executes the full data scraping process based on the provided goatspeak query. Accepts either a goatspeak string or a file path to a goatspeak file.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>A goatspeak string or a file path to a goatspeak file.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[HTMLNode]</code> <p>A list of scraped HTMLNode results.</p> Usage <pre><code>results = Shepherd().herd(\"VISIT 'http://example.com'; SCRAPE 1 p;\")\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>def herd(self, query: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Executes the full data scraping process based on the provided goatspeak query. Accepts either a goatspeak string or a file path to a goatspeak file.\n\n    Args:\n        query (str): A goatspeak string or a file path to a goatspeak file.\n\n    Returns:\n        list: A list of scraped HTMLNode results.\n\n    Usage:\n        ```python\n        results = Shepherd().herd(\"VISIT 'http://example.com'; SCRAPE 1 p;\")\n        ```\n    \"\"\"\n    goatspeak = self._convert_query_to_goatspeak(query)\n\n    results = []\n\n    for block in goatspeak:\n        html = self.sheepdog.fetch(block.fetch_command)\n        root = self.gardener.grow_tree(html)\n        self._query_list_handler(block.query_list, root, results)\n\n    return list(dict.fromkeys(results))\n</code></pre>"},{"location":"core/classes/shepherd/#scrapegoat_core.classes.shepherd.Shepherd.herd_from_html","title":"<code>herd_from_html(query, html)</code>","text":"<p>Grows an HTMLNode tree from raw HTML and executes a goatspeak query on it.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>A goatspeak string or a file path to a goatspeak file.</p> required <code>html</code> <code>str</code> <p>The raw HTML string to be parsed.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[HTMLNode]</code> <p>A list of scraped HTMLNode results.</p> Usage <pre><code>html_content = \"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\"\nresults = Shepherd().herd_from_html(\"SCRAPE 1 p;\", html_content)\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>def herd_from_html(self, query: str, html: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Grows an HTMLNode tree from raw HTML and executes a goatspeak query on it.\n\n    Args:\n        query (str): A goatspeak string or a file path to a goatspeak file.\n        html (str): The raw HTML string to be parsed.\n\n    Returns:\n        list: A list of scraped HTMLNode results.\n\n    Usage:\n        ```python\n        html_content = \"&lt;html&gt;&lt;body&gt;&lt;p&gt;Hello, World!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\"\n        results = Shepherd().herd_from_html(\"SCRAPE 1 p;\", html_content)\n        ```\n    \"\"\"\n    root = self.gardener.grow_tree(html)\n    return self._local_herd(query, root=root)\n</code></pre>"},{"location":"core/classes/shepherd/#scrapegoat_core.classes.shepherd.Shepherd.herd_from_node","title":"<code>herd_from_node(query, root)</code>","text":"<p>Executes a goatspeak query starting from a given HTMLNode.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>A goatspeak string or a file path to a goatspeak file.</p> required <code>root</code> <code>HTMLNode</code> <p>The starting HTMLNode from which to execute the query.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[HTMLNode]</code> <p>A list of scraped HTMLNode results.</p> Usage <pre><code>root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\nresults = Shepherd().herd_from_node(\"SCRAPE 1 p;\", root_node)\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>def herd_from_node(self, query: str, root: \"HTMLNode\") -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Executes a goatspeak query starting from a given HTMLNode.\n\n    Args:\n        query (str): A goatspeak string or a file path to a goatspeak file.\n        root (HTMLNode): The starting HTMLNode from which to execute the query.\n\n    Returns:\n        list: A list of scraped HTMLNode results.\n\n    Usage:\n        ```python\n        root_node = HTMLNode(...)  # Assume this is an initialized HTMLNode\n        results = Shepherd().herd_from_node(\"SCRAPE 1 p;\", root_node)\n        ```\n    \"\"\"\n    return self._local_herd(query, root=root)\n</code></pre>"},{"location":"core/classes/shepherd/#scrapegoat_core.classes.shepherd.Shepherd.herd_from_url","title":"<code>herd_from_url(query, url)</code>","text":"<p>Fetches HTML from a URL, grows an HTMLNode tree, and executes a goatspeak query on it.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>A goatspeak string or a file path to a goatspeak file.</p> required <code>url</code> <code>str</code> <p>The URL from which to fetch HTML content.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[HTMLNode]</code> <p>A list of scraped HTMLNode results.</p> Usage <pre><code>results = Shepherd().herd_from_url(\"SCRAPE 1 p;\", \"http://example.com\")\n</code></pre> Source code in <code>scrapegoat-core/src/scrapegoat_core/classes/shepherd.py</code> <pre><code>def herd_from_url(self, query: str, url: str) -&gt; list[\"HTMLNode\"]: # type: ignore\n    \"\"\"\n    Fetches HTML from a URL, grows an HTMLNode tree, and executes a goatspeak query on it.\n\n    Args:\n        query (str): A goatspeak string or a file path to a goatspeak file.\n        url (str): The URL from which to fetch HTML content.\n\n    Returns:\n        list: A list of scraped HTMLNode results.\n\n    Usage:\n        ```python\n        results = Shepherd().herd_from_url(\"SCRAPE 1 p;\", \"http://example.com\")\n        ```\n    \"\"\"\n    html = self.sheepdog.fetch(url)\n    root = self.gardener.grow_tree(html)\n    return self._local_herd(query, root=root)\n</code></pre>"},{"location":"loom/","title":"Scrapegoat Loom Documentation","text":""},{"location":"loom/#introduction","title":"Introduction","text":"<p>Loom is an optional extension for Scrapegoat that provides a graphical interface for building and running Goatspeak queries. With Loom, you can create complex webscraping queries without writing any code, making it accessible to users of all skill levels.</p>"},{"location":"loom/#loom-features","title":"Loom Features","text":"<ul> <li>Visualize Websites: Load and visualize web pages directly within the Loom interface.</li> <li>Click and Select: Interactively select elements on the page to build your queries.</li> <li>Search Functionality: Use the search bar to quickly find and select elements based on tags, classes, or IDs.</li> <li>Conditional Logic: Add conditional statements to your queries with ease.</li> <li>Export Queries: Export your queries as Goatspeak code for use in your Scrapegoat projects.</li> </ul>"},{"location":"loom/#further-reading","title":"Further Reading","text":"<p>To learn more about Loom and how to use it effectively, please refer to the Loom Class Documentation.</p>"},{"location":"loom/loom/","title":"Loom Class","text":""},{"location":"loom/loom/#loom","title":"Loom","text":"<p>               Bases: <code>App</code></p> <p>The main Loom application class for visualizing HTMLTrees and constructing Goatspeak queries. Uses Textual for the GUI framework.</p> <p>Attributes:</p> Name Type Description <code>CSS_PATH</code> <code>str</code> <p>The path to the CSS file for styling the application.</p> <code>SCREENS</code> <code>dict</code> <p>A dictionary mapping screen names to their corresponding ModalScreen classes.</p> <code>BINDINGS</code> <code>list</code> <p>A list of key bindings for various actions within the application.</p> Source code in <code>scrapegoat-loom/src/scrapegoat_loom/classes/loom.py</code> <pre><code>class Loom(App):\n\t\"\"\"\n\tThe main Loom application class for visualizing HTMLTrees and constructing Goatspeak queries. Uses Textual for the GUI framework.\n\n\tAttributes:\n\t\tCSS_PATH (str): The path to the CSS file for styling the application.\n\t\tSCREENS (dict): A dictionary mapping screen names to their corresponding ModalScreen classes.\n\t\tBINDINGS (list): A list of key bindings for various actions within the application.\n\t\"\"\"\n\tCSS_PATH = str(files(\"scrapegoat_loom\").joinpath(\"gui-styles/tapestry.tcss\"))\n\tSCREENS = {\"find\": FindModal, \"set-url\": SetURLModal, \"add-query\": AppendQueryModal, \"remove-query\": RemoveQueryModal, \"save-as\": SaveAsModal}\n\tBINDINGS = [\n\t\tBinding(\"ctrl+f\", \"push_screen('find')\", \"Search Tree\", tooltip=\"Shows the node search widget.\"),\n\t\tBinding(\"ctrl+u\", \"toggle_set_url\", \"Set URL\", tooltip=\"Shows the URL input widget.\"),\n\t\tBinding(\"ctrl+a\", \"toggle_insert_query\", \"Append Query\", tooltip=\"Appends a new scrape query.\"),\n\t\tBinding(\"ctrl+r\", \"toggle_remove_query\", \"Remove Query\", tooltip=\"Removes a query.\"),\n\t\tBinding(\"ctrl+S\", \"toggle_save_as\", \"Save As\", tooltip=\"Save the query to a new file.\"),\n\t\tBinding(\"ctrl+s\", \"save\", \"Save\", tooltip=\"Save the query.\"),\n\t]\n\n\tdef __init__(self, **kwargs):\n\t\t\"\"\"\n\t\tInitializes the Loom application.\n\n\t\tArgs:\n\t\t\t**kwargs: Additional keyword arguments for the App superclass.\n\t\t\"\"\"\n\t\tsuper().__init__(**kwargs)\n\t\tself.sub_title = \"untitled.goat\"\n\t\tself.prev_url = \"\"\n\t\tself.url = \"\"\n\t\tself.prev_headless_check = False\n\t\tself.url_req_headless = False\n\t\tself.has_tree = False\n\t\tself.nodes = {}\n\t\tself.current_search_nodes = []\n\t\tself.search_node_index = 0\n\t\tself.selected_query = \"\"\n\t\tself.save_path = \"\"\n\t\tself.changes_saved = False\n\n\tdef get_system_commands(self, screen):\n\t\tyield from super().get_system_commands(screen)\n\t\tyield SystemCommand(\"Find\", \"Shows/Hides the node search widget.\", self.toggle_search)\n\t\tyield SystemCommand(\"Set URL\", \"Sets the URL for the Tree Visualizer to pull from.\", self.action_toggle_set_url)\n\t\tyield SystemCommand(\"Append Query\", \"Appends a new scrape query.\", self.action_toggle_insert_query)\n\t\tyield SystemCommand(\"Save As\", \"Save the query to a new file.\", self.action_toggle_save_as)\n\t\tyield SystemCommand(\"Save\", \"Save the query to a file.\", self.action_save)\n\n\tdef _create_tree_from_root_node(self, node) -&gt; Tree:\n\t\tself.nodes = {}\n\t\ttree = None\n\n\t\tfor child in node.preorder_traversal():\n\t\t\tif tree is None:\n\t\t\t\ttree = Tree(f\"&lt;{child.tag_type}&gt;\")\n\t\t\t\ttree.root._html_node_id = child.id\n\t\t\t\tself.nodes[child.id] = NodeWrapper(child, tree.root)\n\t\t\t\tcontinue\n\n\t\t\tnode_label = f\"&lt;{child.tag_type}&gt;\"\n\t\t\tif len(child.body.strip()) &gt; 0:\n\t\t\t\tnode_label += f\" {child.body}\"\n\n\t\t\tbranch = tree.root if child.parent is None else self.nodes[child.parent.id].branch\n\t\t\tbranch.expand()\n\t\t\tbranch.allow_expand = False\n\n\t\t\tif len(child.children) == 0:\n\t\t\t\tchild_branch = branch.add_leaf(node_label)\n\t\t\telse:\n\t\t\t\tchild_branch = branch.add(node_label)\n\n\t\t\tchild_branch._html_node_id = child.id\n\t\t\tself.nodes[child.id] = NodeWrapper(child, child_branch)\n\n\t\treturn tree\n\n\tdef _create_placeholder_tree(self) -&gt; Tree:\n\t\ttree = Tree(\"&lt;No URL Set&gt;\")\n\t\ttree.root.allow_expand = False\n\n\t\treturn tree\n\n\tdef _search_tree(self, search_string:str) -&gt; list[NodeWrapper]:\n\t\treturn_list = []\n\t\tfor node in self.nodes.values():\n\t\t\tif search_string in node:\n\t\t\t\treturn_list.append(node)\n\t\treturn return_list\n\n\tdef _update(self):\n\t\tif len(self.save_path) &gt; 0:\n\t\t\tself.sub_title = self.save_path.split(os.sep)[-1]\n\t\tif not self.changes_saved:\n\t\t\tif len(self.sub_title) &gt; 0:\n\t\t\t\tif self.sub_title[-1] != \"*\":\n\t\t\t\t\tself.sub_title += \"*\"\n\n\tdef action_add_remove_node(self) -&gt; None:\n\t\tif self.has_tree:\n\t\t\tif self.control_panel and self.control_panel.current_node:\n\t\t\t\tif self.control_panel.current_node.get_querying() == False:\n\t\t\t\t\tself.control_panel.add_node()\n\t\t\t\telse:\n\t\t\t\t\tself.control_panel.remove_node()\n\n\tdef toggle_search(self) -&gt; None:\n\t\tself.push_screen(\"find\")\n\n\tdef action_toggle_set_url(self) -&gt; None:\n\t\tself.push_screen(\"set-url\")\n\n\tdef action_toggle_insert_query(self) -&gt; None:\n\t\tif self.has_tree:\n\t\t\tself.push_screen(\"add-query\", lambda x: self.control_panel.append_query(x))\n\n\tdef action_toggle_remove_query(self) -&gt; None:\n\t\tif self.selected_query != None and self.selected_query[:5] != \"VISIT\" and self.has_tree:\n\t\t\tself.push_screen(\"remove-query\", lambda x: self.remove_query(x))\n\n\tdef action_toggle_save_as(self) -&gt; None:\n\t\tself.push_screen(\"save-as\")\n\n\tdef action_save(self) -&gt; None:\n\t\tif len(self.save_path) &gt; 0:\n\t\t\tsave_to_file(self.save_path, self.control_panel.get_query())\n\t\t\tself.changes_saved = True\n\t\telse:\n\t\t\tself.push_screen(\"save-as\")\n\n\tdef remove_query(self, confirm) -&gt; None:\n\t\tif confirm:\n\t\t\tself.control_panel.remove_query(self.selected_query)\n\t\t\tself.selected_query = None\n\n\tasync def update_url(self) -&gt; None:\n\t\tif self.url == self.prev_url and self.prev_headless_check == self.url_req_headless:\n\t\t\treturn\n\n\t\ttry:\n\t\t\thtml: str = None\n\n\t\t\tif not self.url_req_headless:\n\t\t\t\thtml = Sheepdog().fetch(self.url)\n\t\t\telif self.url_req_headless:\n\t\t\t\tdog = HeadlessSheepdog()\n\t\t\t\thtml = await asyncio.to_thread(dog.fetch, self.url)\n\n\t\t\troot = Gardener().grow_tree(html)\n\n\t\t\tprev_tree = self.query_one(Tree)\n\t\t\tnew_tree = self._create_tree_from_root_node(root)\n\n\t\t\tprev_tree.root = new_tree.root\n\t\t\tself.has_tree = True\n\t\t\tself.control_panel.update_url(self.url)\n\t\t\tself.prev_url = self.url\n\t\t\tself.prev_headless_check = self.url_req_headless\n\t\t\tself.control_panel.update_node(self.nodes[new_tree.root._html_node_id])\n\t\texcept HTTPError:\n\t\t\tself.notify(\"The URL you entered could not be reached. Please check your internet connection and try again.\", title=\"Could Not Resolve URL\", severity=\"warning\", timeout=10)\n\t\texcept MissingSchema:\n\t\t\tself.notify(\"The URL you entered is invalid. Please try again.\", title=\"Could Not Resolve URL\", severity=\"warning\", timeout=10)\n\t\texcept ScrapegoatPlaywrightException:\n\t\t\tself.notify(\"Playwright is not installed. Please install it with 'pip install playwright' and 'playwright install'.\", title=\"Module Not Found\", severity=\"information\", timeout=10)\n\t\texcept ScrapegoatFetchException as e:\n\t\t\tself.notify(f\"{e}\", title=\"Playwright Error\", severity=\"error\", timeout=10)\n\t\texcept:\n\t\t\tself.notify(\"An unknown error occured. Please try again.\", title=\"Unknown Error\", severity=\"error\", timeout=10)\n\n\tdef on_mount(self) -&gt; None:\n\t\tself.set_interval(0.3, self._update)\n\n\tdef on_tree_node_highlighted(self, event: Tree.NodeHighlighted) -&gt; None:\n\t\tif self.has_tree:\n\t\t\tif self.control_panel:\n\t\t\t\tself.control_panel.update_node(self.nodes.get(event.node._html_node_id, None))\n\n\tasync def on_button_pressed(self, event: Button.Pressed) -&gt; None:\n\t\tif event.button.id == \"url-confirm\":\n\t\t\tawait self.update_url()\n\t\telif event.button.id == \"save-as-confirm\":\n\t\t\tself.action_save()\n\n\t\tif self.has_tree:\n\t\t\tif event.button.id == \"node-add-remove\":\n\t\t\t\tself.action_add_remove_node()\n\t\t\telif event.button.id == \"copy-query\":\n\t\t\t\twrite_to_clipboard(self.control_panel.get_query())\n\t\t\telif event.button.id == \"find-node-next\":\n\t\t\t\tif len(self.current_search_nodes) &gt; 0:\n\t\t\t\t\tself.search_node_index += 1\n\t\t\t\t\tif self.search_node_index &gt;= len(self.current_search_nodes):\n\t\t\t\t\t\tself.search_node_index = 0\n\n\t\t\t\t\tself.query_one(Tree).move_cursor(self.current_search_nodes[self.search_node_index].branch, True)\n\t\t\telif event.button.id == \"find-node-prev\":\n\t\t\t\tif len(self.current_search_nodes) &gt; 0:\n\t\t\t\t\tself.search_node_index -= 1\n\t\t\t\t\tif self.search_node_index &lt; 0:\n\t\t\t\t\t\tself.search_node_index = len(self.current_search_nodes) - 1\n\n\t\t\t\t\tself.query_one(Tree).move_cursor(self.current_search_nodes[self.search_node_index].branch, True)\n\n\tdef on_checkbox_changed(self, event: Checkbox.Changed) -&gt; None:\n\t\tif event.checkbox.id == \"url-headless-check\":\n\t\t\tself.url_req_headless = event.value\n\n\t\tif self.has_tree:\n\t\t\tif \"flag\" == event.checkbox.id[0:4]:\n\t\t\t\tif event.checkbox.value:\n\t\t\t\t\tself.control_panel.append_flag(str(event.checkbox.label))\n\t\t\t\telse:\n\t\t\t\t\tself.control_panel.remove_flag(str(event.checkbox.label))\n\t\t\telif \"html-attribute\" == event.checkbox.id[0:14] or \"node-attribute\" == event.checkbox.id[0:14]:\n\t\t\t\tif event.checkbox.value:\n\t\t\t\t\tself.control_panel.append_attribute(str(event.checkbox.label))\n\t\t\t\telse:\n\t\t\t\t\tself.control_panel.remove_attribute(str(event.checkbox.label))\n\n\tdef on_input_changed(self, event: Input.Changed) -&gt; None:\n\t\tif event.input.id == \"url-input\":\n\t\t\tself.url = event.input.value\n\t\telif event.input.id == \"save-as-input\":\n\t\t\tself.save_path = event.input.value\n\n\t\tif self.has_tree:\n\t\t\tif event.input.id == \"find-node-input\":\n\t\t\t\tself.current_search_nodes = self._search_tree(event.input.value)\n\t\t\t\tif len(self.current_search_nodes) &gt; 0:\n\t\t\t\t\tself.search_node_index = 0\n\t\t\t\t\tself.query_one(Tree).move_cursor(self.current_search_nodes[self.search_node_index].branch, True)\n\n\tdef on_list_view_selected(self, event: ListView.Selected):\n\t\tif event.list_view.id == \"query-view\":\n\t\t\tself.selected_query = event.item.query_one(Static).render()\n\t\telse:\n\t\t\tself.selected_query = None\n\n\tdef compose(self):\n\t\tyield Header(name=\"ScrapeGoat\", icon=\"\ud83d\udc10\")\n\t\tdom_tree = self._create_placeholder_tree()\n\t\tctrl = ControlPanel()\n\t\tself.control_panel = ctrl\n\t\tctrl.loom = self\n\n\t\tyield dom_tree\n\t\tyield ctrl\n\n\t\tyield Footer()\n\n\tdef weave(self) -&gt; None:\n\t\t\"\"\"\n\t\tThe main entry point to run the Loom application.\n\n\t\tUsage:\n\t\t\t```python\n\t\t\tLoom().weave()\n\t\t\t```\n\t\t\"\"\"\n\t\tself.run()\n</code></pre>"},{"location":"loom/loom/#scrapegoat_loom.classes.loom.Loom.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the Loom application.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments for the App superclass.</p> <code>{}</code> Source code in <code>scrapegoat-loom/src/scrapegoat_loom/classes/loom.py</code> <pre><code>def __init__(self, **kwargs):\n\t\"\"\"\n\tInitializes the Loom application.\n\n\tArgs:\n\t\t**kwargs: Additional keyword arguments for the App superclass.\n\t\"\"\"\n\tsuper().__init__(**kwargs)\n\tself.sub_title = \"untitled.goat\"\n\tself.prev_url = \"\"\n\tself.url = \"\"\n\tself.prev_headless_check = False\n\tself.url_req_headless = False\n\tself.has_tree = False\n\tself.nodes = {}\n\tself.current_search_nodes = []\n\tself.search_node_index = 0\n\tself.selected_query = \"\"\n\tself.save_path = \"\"\n\tself.changes_saved = False\n</code></pre>"},{"location":"loom/loom/#scrapegoat_loom.classes.loom.Loom.weave","title":"<code>weave()</code>","text":"<p>The main entry point to run the Loom application.</p> Usage <pre><code>Loom().weave()\n</code></pre> Source code in <code>scrapegoat-loom/src/scrapegoat_loom/classes/loom.py</code> <pre><code>def weave(self) -&gt; None:\n\t\"\"\"\n\tThe main entry point to run the Loom application.\n\n\tUsage:\n\t\t```python\n\t\tLoom().weave()\n\t\t```\n\t\"\"\"\n\tself.run()\n</code></pre>"}]}